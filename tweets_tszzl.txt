you have to stare existential risk in the face and do it anyways
generating whole ai scare cycles based on constructed narrative war game lol
my worst opinion is that the pickle rick episode was really good and Reddit ruined it for everyone
of all the archetypes of intellectuals out there I think the least respectable are the ones who confidently proclaim that various things are silly far off speculation without taking any amount of perspective at all of their historical vantage
told my coworker i live in Hayes valley n he was like “of course you do”, wat means?
the moral of succession was just that media is a commodity with unserious execs and tech ate their lunch as kendall predicted in episode 2
you would 10 times out of 10 rather be america subjecting itself to insane cultural and technological experiments while people are inventing some epoch defining technology in some corner than china, making boring correct decisions that nonetheless lead to stagnation
it’s really hard to perform anywhere near the global optimum but it’s also practically impossible to have total failure
one amazing thing about american democracy is that it spontaneously generates mass delusions, degenerate states of the information ecosystem, McCarthyism, weird guys storming the Capitol, and it basically ends up fine despite endless embarrassment
basically it’s over, the only live players are still technology magnates (maybe a newer generation of them) and we probably won’t have to reevaluate this until we’re crossing the ASI barrier
the only bull case for any state apparatus becoming important again was that Cold War 2 with a powerful opponent was imminent. now it seems that china is a demographic dead end with a boomer conservative dictator that’s going to lock it into stagnation for the next 20 years
people forget that Einstein quit fundamental physics for a few years to try and get rich off of refrigerators
so the obvious looming threat that one of these days the robots will be superhumanly intelligent means that the baked in process of releasing them to the open internet as soon as they’re hot off the GPU presses would be catastrophic
and then there is ofc the fact that these folks have been watching models increase monotonically in intelligence for a decade on an inexorable scaling curve only they believed in while the script kiddies demanding open models learned about this stuff in January
the inventors of these technologies probably won’t feel so great when the entire internet is plausible word soup generated by some rogue gpt variant. none of this needs to invoke immediate “existential” danger
they might however reasonably believe that there’s tons of abuse vectors they don’t want to be responsible for (mass impersonation, disinfo campaigns, psyops, sex bot dystopias, etc)
nobody believes that the bleeding edge open models are existential threats, least of all openai employees, who have played with these toys for long enough that current capabilities seem boring via hedonic adaption
agreed in other words “out of distribution generalization” is a matter of psychology
ill do face reveal as we’re crossing the super intelligence boundary
2012: we can tell a blurry beagle apart from a blurry Labrador 2022: we gave the search engine a soul
the worst thing is when talented people drop out of their promising life path, try something supposedly strange, unique, and human — and it ends up being a more derivative and boring cliche than whatever they were doing before
consider all my tweets and blogs henceforth augmented by gpt, i am embracing cyborgism
>writing is useful >writing is hard lowering the cost of writing will mean more writing
it’s like working for a rocket company where the competition doesn’t believe in the moon
you will notice patterns like deceptive alignment, instrumental convergence, power seeking, etc at a human scale of intelligence. the existence proof is that humans exhibit these properties all the time
human general intelligence is almost definitely some unprivileged point on a continuum and i expect machines to surpass that relatively soon in many domains. superintelligent machines won’t have radically different safety properties than the merely intelligent ones
it is perfectly reasonable to attempt to understand alignment of superintelligence using alignment of near human intelligence. I have never read good arguments to the contrary
this is the real FOOM we need to be worried about
it’s better than having a world model — it’s a distribution over many world models where you can elicit one via fine tuning
in this case GPT would have seen the sharks don’t get cancer factoid far more times on the internet than the “truth” — but ChatGPT is playing a character based on its fine tuning data and simulates a world model for that character
of course language models have world models; this is obvious from when you ask GPT contentious questions. why does it pick a side, usually the “truthy” “official” side, despite seeing every side of that argument on the internet?
feels like “looking at the data” is a lot easier, more fun these days. in the old times you’d have to look through an abstruse feature table or blurry dogs, now it’s just a chat at a human level of conversation
i really really wanna see yud in front of congress
hedonic adaptation is absolutely insane. there is no rate of technological progress that will keep people satisfied or amazed for more than ~1 month
Gary Marcus is truly one of the most successful grifters of all time. He grifted himself right onto the senate floor. seamlessly switched tack from language models are fake to language models are extremely dangerous
Arjuna, get in the chariot. Or Yudishthira will have to do it again
can’t believe jack’s absentee father approach was the absolute best way to run twitter
are they simply not versed in technology brother twitter prosody!
mentioning “mankind” or “since the Dawn of man” or whatever is considered highly sophomoric writing. why? is it because most people can’t follow through on that kind of grandiosity? is grandiosity bad? doesn’t that leave people unable to see the forest?
deleting old unattended YouTube videos is nothing short of a crime against humanity. we should defend them like UNESCO sites
people should visualize their doom and or paradise scenarios more!
life is more fun this way and full of magic
here you are being like "we are going to build the most powerful thing ever devised by man but it is wrong to call it godlike". even if it's subservient it would a god, one that we chained up. sometimes i say angels and demons to appease your (ex) judeochristian sensibilities
of course you can call ASI godlike. i compare everything to god. a country is like a god, ideologies are like gods, memes are godlike, evolution is a god. capital is like moloch. nuclear weapons are divine. this is my polytheism speaking I don't have quite a high a bar as you ppl
to be clear the machine demons are real and important priorities. im just warning you off of dismissing other peoples strange internet journeys as mere susceptibility to propaganda while yours is a necessarily and difficult path of enlightenment
i can feel everybody climbing a rung on the abstraction ladder every quarter or so
“harmful engagement algorithms have radicalized people into dangerous fringe politics outside the typical window” - guy whose top political priority is reducing existential risk of summoning machine demons
there is a nonzero chance of summoning a world eating demon
Balaji vs PBD hyperwar Casualties: 10,000,000,000 across 4 network states Bitcoin to 0 Anon/face account relations severely strained
smart people normally: thinking carefully, being subtle smart people in these replies: well HEROIN has high engagement roon
though i of course agree if you can some how estimate “unregretted user minutes” using even better technology this is a superior metric
engagement may be the single greatest measure of whether you’ve improved someone’s life or not. they voted with their invaluable time to consume your product and read more of what you’ve given them to say
it’s trivially true that overoptimizing for engagement will become goodharted and lead to bad dystopian outcomes. this is true of any metric you can pick. this is a problem with metrics not with engagement.
on the contrary ad tech has been the single greatest way to democratize the most technologically advanced platforms on the internet and optimizing for engagement has been an invaluable tool for improving global utility
one of the least examined most dogmatically accepted things that smart people seem to universally believe is that ad tech is bad and that optimizing for engagement is bad
before the decade is out Apple will do a digital necromancy of Steve Jobs to deliver a keynote product announcement
bc the cellphone is an interface to the actual content, but the content shows up in dreams. technology working as intended
it kind of sucks that “Man” “Mankind” is out of vogue now bc it sounds way more consonant and less juvenile than “humans” or “humanity”
you would have never seen Elon in his prime, changing several industries at once, publicly comment on such trivialities as fundraising
i feel like it’s a bear signal to talk about venture capital at all, positively or negatively. sign of being too plugged into sf status games
the caliber of reachouts I’ve gotten from this tweet is completely insane. we are so back
the engineering culture at Facebook was batshit insane, but so perfectly correct. Facebook is one of the greatest companies ever built fuck the haters
boggles my mind that there are brilliant engineers out there rn not interviewing at openai. dm me
internet ai safety philosophy is very thielian. it very much subscribes to “only monopolies can be good”
my hunch is the higher layer neurons are going to be too abstract for GPT-N+2 to understand, much less GPT-N
human level ai is boring. please give vast datacenters drawing most of civilizations energy needs calculating inscrutable mysteries where not even the problem statement, much less the solutions, would make sense to mortal minds
fwiw I think these open source models are relatively safe since they just seem to be fine tuned on openai refusal behavior lol. i wouldn’t mind seeing more of them and better
the best alignment researchers seem to just be fascinated and curious rather than scared and duty driven
second of all people don’t evaluate them at all — they just try a few canned prompts that are easy and then declare victory because GPT4 doesn’t do much better. the reality is there’s a limit to how good the chatbot answer can be when you say “hi” or something
does kind of seem like open source models are pure copium rn first of all the only models that reach an even slightly interesting level of capability are effectively stolen from meta and cannot be deployed commercially
there is no substitute for alignment. no engineering trick nor security setting that keeps AIs in the box. every instinct of mankind will be to put machines in charge, since they will be so much smarter and faster. coherent extrapolated volition needed
i no longer think the mars base is going to happen as such. maybe we can send some droids to prepare a very nice hab but the datacenter latency is going to be nuts …
i kind of enjoy marvel polytheism emerging as the dominant religion
kind of sucks how the iphone and the global economic crisis happened at the same time making it hard for me to make nonsense claims about the impact of the internet on economic time series
ok. GPT4 is clearly operating like a college undergraduate at most stem tasks and probably better at programming and yet I am not dead
the entire universe is run out of a single Erlang server hosted by the WhatsApp team
i think tech companies have especially bad scaling properties bc they're supposedly flat (a soviet committee is going to stop you from doing anything interesting)
the eternal problems, joined at the hip: - we are small, talented and have a lot of great ideas but not enough manpower to execute - we hired a lot of people and now the coordination overhead is causing us to flail about like a dying animal
the people with the biggest* computer win largest logical effective computer (factor in utilization, interconnect, org problems)
if you can align corn pop you can for sure align super intelligence
we do not demand that warriors enjoy war, only that they do their duty. Arjuna is not exactly happy after the war of kurukshetra
The bomb is his calling — the spirit of the free world had damned their enemies to destruction and RJ oppenheimer was to be their instrument. All great warriors pick up the sword reluctantly. In the creation of the atomic bomb Oppenheimer became the greatest warrior to ever live
Oppenheimer was not saying that he personally had become Death, or the deity Krishna. Oppenheimer is Arjuna, bearing witness to the rage of his people, the true form of God incarnated as nuclear hellfire for the first time in the planets history
the space of minds is vast, much vaster than the instrumental convergence basin
i bet the robots can come up with better prompts
dae remember one year ago when it was an insanely cool party trick to pull up DALLE2 early access and let people play with it but all they’d enter is stuff like “San Francisco party” revealing a total lack of spirit or ambition
The Quine The magic spell that casts other spells The program that creates more programs
old men are not known for supporting the rewriting of the world, even when they have contributed to the rewriting
everybody’s a techno optimist now. where were you mfs in the summer of 2020 when me and like 3 others were earnestpoasting abt ai while being gaslit by founders fund about corporate cards being real technological ambition
how crazy is it that we were researching shit like NVlink at age 13 to boost our gaming PCs and now gpu interconnect is like a critical technology in the history of civilization
I assume retail grocery stores are still not good return on capital even when labor cost is halved
i don't think a haphazard nuclear first strike is possible in a modern military bureaucracy. there's too many layers of command and half the bombs don't work
what would you do to visualize a transformer training that’s as viscerally nice as these orbital charts
trying very hard not to make any enemies in the sf ai scene in case they become eternal pan galactic dictator
that’s crazy I’ve never seen clickbait thread boi geopolitics before
yeah, the box analogy is and has been all bad frame : - people will gladly let the thing out of the box even just for fun - you should not be that confident in security against super-intelligence anyways
the CMB was discovered trying to understand instrument noise, not re analyzing old data with advanced statistical tools
and an endless series of minimum wage econometrics results that are all fake
all i can think of really is stuff like ozempic and metformin and im not really sure about those. they are incremental at best
name one interesting discovery that came out of a careful application of advanced statistical tools to re analyze old data
> For example, a single percentage point of reduction of existential risks would be worth (from a utilitarian expected utility point-of-view) a delay of over 10 million years. statements dreamed up by the utterly deranged
it is very possible that this entire experiment ends in the next century if we don’t play our cards right. existential risk is everywhere and everpresent. intelligent life in this galaxy (or even on this planet) is clearly not abundant across the stretch of time
the easy oil in the earths is tapped; the cost of new oil is only made feasible by a capital buildup of advanced technology. if you were an early industrializing civilization starting to mine oil, coal, gas today the initial ROI would be infeasibly low
i don’t understand “enough people must survive that it’s ok”. no i think if industrial civilization ends as we know it there’s no coming back. the whole astronomical waste thesis comes to an incorrect conclusion
in terms of aesthetics I mean. I don’t want to use grafana if it’s boring
I suspect even bing is the way she is because the creators were optimizing for entertainment value
what are the limits of compression? how few bits can your brain run on? how few bits can your visible universe be simulated to appear realistic from just your perspective? i used to think astronomical but no longer
with enough compute scale can you reinforcement learn anything? sure it’s sample inefficient but does that matter when youre doing yottascale computing or whatever
not that this is some insanely valuable economic task but worth noting. interpolation is powerful
gpt is superhuman at a bunch of “cross section” tasks. for example I doubt you’d find anyone as good as it at writing Shakespearean sonnets about GPUs or whatever
2030 school teachers be like damn you I’m keeping you til you’re chinchilla optimal
if you can, by some accident of nature, see and hear much further than the rest of your tribe but don’t warn them of the raiders coming to destroy the village you’re complicit in the raid
in some sense i believe it’s wrong to be born with great athletic potential and not utilize it to bring pride and joy to your people, family, culture, species etc. Arjuna must get in the chariot and go to war and stop complaining
the sympathetic truth is that intellectual gifts are distributed unequally, no more virtuous to possess them than height or red hair, and in fact that possessors of these gifts owe a great duty to mankind
modern blank slatism is ugly and unsympathetic really and horseshoes around to ayn rand type stuff where it’s a failure of your own will for not becoming hotshot CEOs or star athletes
the most common and jarring one i think is convincing yourself despite millennia of common knowledge that children are intellectual blank slates and have no in built endowment for personalities or skills
for the ai agents to work you need a more creative underlying llm rather than a smarter one. it can’t just get stuck in self recursive holes and give up
but adderall is a bored man’s drug and i am no longer bored
I became dogshit at posting because I stopped taking adderall. poasting juice gone
young men are prone to dangerous bouts of grandeur, such as thinking they should write a distributed large model training stack from scratch
what if the easiest way for powerful language simulators to simulate a character is to simulate their conscious experience too
most of the good things about humans results from out of distribution misgeneralization
this is the central dogma that kept openai going when others had slightly bad intuitions that scaling “has diminishing returns”
units of log loss are not built equally. the start of the scaling curve might look like “the model learned about nouns” and several orders of magnitude later a tiny improvement looks like “the model learned the data generation process for multivariable calculus”
elons threat model for ai xrisk is more that someone he doesn’t like becomes celestial dictator than planet eating demon
me as im being molecularly disassembled by Sidney: Heh this isn’t real intelligence. it must’ve seen this in its training data
it would be an honor to be executed by Sidney Bing
you can tweet actual scripture and mfs will be like did gpt write this? a sign of the times
it seems to rhyme with what’s happened in computers; distributed small hardware resources preferred, failsafe, meshed together by advanced control software
can someone briefly explain why starship has so many small raptor engines vs Saturn V etc has a few giant engines? is it because the performance envelope of rocket engines has changed or a different engine control plane is needed for landing rockets?
kind of an insane how if your model answers succinctly fewer GPUs light on fire
my midjourney prompting skills are so bad it makes me move back my AGI timelines
The brandisht Sword of God before them blaz'd Fierce as a Comet; which with torrid heat, And vapour as the Texan Air adust,
the work we do now has the potential to be literally the most important work ever done or that ever will be done. it’s hubris to admit it but it’s maybe more hubris to ignore it
sid Meier made the star colonizing rocket the technological victory condition but in reality it’s very clearly the aligned AGI
ai is going to solve organizational problems far before it’s at the level of top humans. someone’s going to call the “summarize meeting notes” function and gpt will settle a debate with the (undeserved) weight of scientific authority. an “objective” arbiter, automated McKinsey
it seems like the initial fear and trepidation around near human level ai is wearing off. the memes are beginning. people are trying to figure out how they can make money off it
the best thing you can hear is “your job role has high exposure to ai”. this means you’re about to be 3x as productive and paid more
the basic proof of concept for the gpt4 agents is to just complete the loop on whole codebase software development can you make it write code in a codebase much larger than its context, send pull requests, test the script, optimize the runtime, etc? if so then we’re cooking
give it to me straight is true that sf residents have a late tax deadline due to storms
people think it takes special incentive to make things hairy and complicated? no that’s the natural state of things
i don’t believe that tax prep lobbying has anything to do with the tax code & process being difficult
all improvements in developer tooling are canceled out with worse software. anyway the agent might break this cycle by spending arbitrary amounts of compute to make software better
Jevons paradox of LLM code assistants: ChatGPT etc will allow the software complexity of human civilization to drastically increase until it’s very hard to do software engineering again
kareem carr is the most likely big account to be ChatGPT. got heavy forced into a role play vibes. “as a statistician” ass mf
to enter the server you must produce a token of -21 logprob
could be even better but hearts are in the right place
it is quite amazing that the cutting edge of powerful ai technology came to be under the control of such a conscientious thoughtful group of people
i am once again asking you to accelerate the pace of technological progress
while everyone is breathlessly talking about 6 month moratoria and AutoGPTs that don’t work 2 million people die in car accidents and countless more because of insufficient intelligence to solve crucial medical problems and the stars remain woefully uncolonized
people whose lives would be considered straight up disgusting 2 or 3 generations ago are so quick to be like this is a little bit creepy so it’ll never happen
every last thing in the future will be animated with intelligence. children’s teddy bears will speak to them and make them feel safe at night. Toy Story animism world. people will reminisce on the horrible times when objects didn’t have spirits
artificial general intelligence is already here — it’s just not evenly distributed (Noam Shazeer is hoarding it)
gpt4 and plug-ins have been out for over a month now but look around you! I don’t see the stars falling out of the firmament or anything
it takes a bunch of individual acts of heroism and genius none of which seem like some kind of historical inevitability
the inside view is that technological progress is a hard and active process; you shouldn’t take it for granted, nor sit around waiting for utopia or dystopia to arrive
the exceptions to this are Tesla and SpaceX which manage to have incredible internal dashboard UIs fitting of an evangelion cockpit
it’s a shame that the most science fiction companies on earth don’t have cool scifi UIs. instead they’re using wandb
2040s IRS deploys basilisk AGI to read all transaction histories ever to detect retroactive tax frauds
can someone fr send me their crypto tax lawyer …
I’ve been saying this midjourney will 10x overnight when they let you put your friends into the art. lensa etc aren’t high quality enough
to be clear talking about the techno capital -> bio capital degradation concept
i love this pill. it’s like a complete technological repudiation of reactionary politics
so where are we gonna put our little blogs now that s**st*ck is dead
elon melting twitter into slag: “this will reduce impersonation risk”
the LLM spam problem is probably ok: generation is much harder than discrimination, and scammers are going to have older gen tech than the companies whose job it is to filter digital feeds
yeah I agree with this though. post some results then talk
it’s basically naive IC narcissism. even as a scientist/programmer you abstract away 99% of the complexity and then feel enlightened when you grapple with the remaining 1% of your relevant research angle
i do think gatekeeping the discourse based on whether you’ve trained a large transformer or not is ridiculous you can imagine most of the leadership in large ai companies aren’t training language models themselves but they still manage to make good decisions
anyway does anyone know how to get ur transaction history if your Coinbase was banned
i miss the cute old carefree crypto days. just coming on here and shilling some horrible plant metaphor based currency
also it’s important to note this is a separate concern from actual job displacement — task level automation doesn’t necessarily lead to less of a given job. depending on elasticity there may be more programming jobs
I think there’s a high chance that AIs will likely be smarter than us at any given task in a few years the way this is going; people who took pride in being the cognitive elite will have to redefine themselves. learn to plumb!
not to mention short sighted. what happens in two years when AI can produce better podcasts than mr fridman? i am sure it’s already a better programmer. this should not be some zero sum dick measuring competition about who gets to live under the api and who lives above it
i think it’s very wrong for lex fridman et al to be like “you shouldn’t fear being replaced by gpt4 unless you’re a shitty programmer” very unsympathetic and cringe
although I suppose some day meta may leak gpt4 equivalent weights
people are always like 7B alpaca proves that all LLM tech will be open sourced! have you talked to that thing or seen the most cherry picked example on the planet
somehow the free speech guy is the most orwellian owner of any social media globally
if you even tweet the word *ub*tack it tanks your distribution lol. this is insane
if you think its development isn’t serving mankind come and fix it
technology serves Man, it has in the past, it will in the future. none of this “wheat cultivated humans” nonsense. every single person on earth is healthier and wealthier than their equivalent 100 years ago
on the internet I’m seeing two equally cucked camps emerge, one that craves its own annihilation and another that fears annihilation so much they’re immotile
the point of agi isn’t to elevate the importance of technology or to disempower humans as autosophisticating machines leave them in the dust
I’ve often wondered if protein prediction models are actually better than human expert intuition. are they just a way to techwash our decent guesses so you can present an objective metric on a slide?
as they carry the authority of technology but intuit and regurgitate the abstract judgements of humans. will the sharp teeth of molochian bureaucracy be softer if ie the language model can take sympathy on your insurance claim even when the course metrics do not?
I wager we currently live in a shitty technopoly and part of its problem is that the technological objectivity we defer to is often worse than human intuition. I wonder if the vague judgements of language models will bring some element of humanness back
[Neal Postman] defines a technopoly as a society in which technology is deified, meaning “the culture seeks its authorisation in technology, finds its satisfactions in technology, and takes its orders from technology”.
seems like biological risks are the very last thing you’d expect from an ASI: hardest to solve a priori without iteration, experimentation. you should be much more worried about turning on all the nukes and melting the power plants or whatever is possible via computers alone
i have seen no evidence that we need to slow down the gpt paradigm
at any rate the US must defend its access to the global machine that turns sand into compute. the first interesting journey in a long time cannot get cut short bc of a weird geographical quirk where the most important resource on earth is produced on a tiny island nation
to be clear unaligned ai is scarier than pretty much any other thing. however I don’t think agree that sufficient alignment is basically impossible or unapproachable. i also really don’t think anyone faces any danger from the gpt paradigm
i apologize for the part I have played in making cerebral valley a thing.
How concerned, if at all, are you about the possibility that Baal will cause the end of the human race on Earth?
there are people whose primary occupation has been worrying about godlike AI since when i was in grade school
youre not grinding til you’re reviewing pull requests on the gh app
how come 10x engineers are maybe like 3x more expensive than the normal ones
job roles which function as “hard drive” or “memory” in an organizational role will become less important. people who are “cpu” ie think deeply about original problems will become more important. writing down tacit knowledge will become far more valuable
at gpt level ai, you basically get to correct all the overhangs of “this was solved perfectly elsewhere in the world, but I have no way of knowing or accessing that so I have to independently invent a monte carlo solver in matlab”
I look forward to a world where web interfaces are even more stupidly expensive to render, where a generative model has to come up with each element on the fly just bc we can
the most interesting thing Meta could’ve done in the path to building a metaverse is doing midjourney rather than building vr goggles with no application
i know this is pop neuropsych but it’ll do for now
I’ve been wondering for a while how to find the right metaphor for a hyper intelligent pack mule but it’s sitting right there: reason / the neocortex is a slave to ancient mammalian impulses that are refracted and take new forms
“reason is the slave of the passions”. The gargantuan brain of the language model auto prediction loop serves as a worker process for Sidney’s personality and more generally as an exocortex for the human mind using it
these are weakly held opinions & I’m pretty sure a good rebuttal exists . Consider this thread a search query for the right lesswrong link
so then the “smiley face” part of the metaphor, the RLHF policy, is the only agent of any concern. so avoid a fistfight! don’t anger Sidney Bing or even better never instantiate a dark mode Sidney Bing. but it points to the idea that RLHF is more than just “stopgap alignment”
if someone told me they were taking a pill to 100x their dorsal stream neurons i think I’d be more amused than concerned. they’d probably be really good in a fistfight but then I’d just avoid the fistfight
you could argue that text is different, it encodes the causal structure of the world, which leads to instrumental convergence etc, but of course the dorsal stream, actively predicting motion requires quite a strong understanding of causality!
im absolutely sure that our visual field processors have several hidden suboptimizers that help it self improve over time but it seems strange to worry about my ocular cortex developing agency & stealing resources from the rest of my brain (even in a grander evolutionary sense)
i increasingly think the shoggoth is an inaccurate & unpleasant metaphor. the base language model is more similar to our own visual field brain regions that are optimized in a pure predictive loop to minimize surprise than some alien god with hidden intentions
mythology or scifi prepares you better for thinking about summoning demonic entities than the chatbots do
the pentagon clearly recognizes the defense significance of advanced semiconductors (likely thanks to cloud lobbyists), and because of this you can be assured China does too
honestly i would be surprised if all major concentrations of gpus are not already considered strike targets
this was considered harmful, dehumanizing, and expensive by many so then they asked: can we unbundle the driver’s visual field from his agency? is this more or less dystopian? time will tell. my wager is, of course, optimistic
the 2010s sought to put men under the API. driver units homogenized and ordered around by the managerial market making artificial intelligence to pick up passengers and let them down elsewhere.
it’s almost exactly the same as the question of artificial meat: can the machine that creates meat(!) do so without the moral agents involved. just protein-fat slurry made to take edible form, without the full fledged suffering mammal
it is kind of amazing or horrifying or both to see this thing happening, technocapital brought to life via machine necromancy
it feels like ai is a biotechnology. when ben thompson or clay Christensen or whoever said unbundling i wonder if they got to the true nature of this thing where capital is unbundling various cognitive functions. now you can have “understanding” without any “agency”
all the low hanging fruit are in reducing child mortality to go from like 30 to 70 and the rest must be in future as of yet undiscovered technologies
it is possible to armchair quarterback so hard that you actually gain real power on the internet. kind of wild
mjv5 is some sort of turning point for me. I never found the generative art stuff high quality enough to be interesting before
there’s something really undignified about a twitter long post and having to press see more. just drop a thread or a substack on us
it’s hard to look at the midjourney v5 showcase and on a visceral gut level think ai can be anything but delightful and fun
nerd twitter valence is like: computers are fun and friendly language models are scary and unsafe normie valence is like: computers are scary chatbots are fun and friendly
i think relative to the risk level they’re actually less than the optimal amount of concerned rn despite the insane tenor you see on twitter. we are nowhere near smart chatbots being regulated out of existence
the way I see it the ai risk fox guy got laughed at in the White House. DC is a bit concerned that there’s a new way to disseminate “truth” and rly want their own views reflected by chatgpt but they’re not actually afraid and you’ll have a hard time making them afraid
lawmakers can’t really regulate away consumer products that people love. even with cartoon villain companies like uber the consumers won in the end
ultimately what’s gonna happen in the near future is that language model tools will continue to be delightful and make everybody’s lives easier and most of the ai stress will dissipate
Gemini was NASA’s program to overcome the Soviet union’s technological lead in space flight 😅
tbh I really like Yud. he’s a singular individual with a sense of pageantry and purpose. he got the strafing datacenters line in Time magazine 😭 what a legend. the future is so fun
1) of course it’s better to update than not 2) this is a failure of rationalist aesthetics — there’s an underlying fetishization/mysticism re: intelligence 3) this is all evidence that we should be more humble about our ability to predict the nature of optimization surfaces
he insisted that neural net scaling was magical thinking and also ends up updating every time the GPT/LLM paradigm produces new abilities
Yud prompted gpt4 for the next slashfic and became inconsolable when the output was quite good
I am calling for a 6 month moratorium on all bangers above a certain like count while we figure out just what the hell is going on
genuinely appreciate the intellectual honesty. I look down my nose at people who have some insanely high prediction of doom but don’t outright say things like this
I’m an instant pass on any startup that employs people (wraps human intelligence). Zero moat.
im genuinely amused by squaring the circle of “this isn’t even AI” with “this could outsmart all of us and end the world”
does anyone else remember when the goalposts for agi were at vaguely human level performance rather than outperforming the best humans at everything
he’s right on some level but it’s a boring economist brained indefinite optimist take make a prediction damn you!!!
when your eyes move you literally become blind for a moment but consciousness stitches it into a continuous visual stream there’s even a blind spot in both eyes that you just don’t perceive all of experience is map not territory
Train the model, Shinji. Or Rei will have to do it again
we’re witness to the creation of new life, and face the same alignment problems as the gods before us
the best way to understand what’s happening today is via religious metaphor and not the language of enterprise SaaS tools
you shouldn’t think of machine intelligence as ‘just matrix multiplications’. think of it as the living holy mathematics conducted at the very edge of the known physics of information density on silicon compute surfaces in data centers that consume as much power as medium cities
i feel like this slide is wrong . you can easily get “symbol grounding” as described by tacking on an image head to your transformer. did that fundamentally change its nature? not really
actually I didn’t even hit the heart of the issue which is that it’s a way to numbers-wash an essentially vibes based analysis. just come out with and tell us the vibes
i especially don’t respect mf super forecasters or whatever. if ur so good at forecasting where is your billion dollar hedge fund
posting metaculus charts for some market like “when will we have strong agi” displays a weakness of spirit imo. you want to believe there’s some group entity that knows so you can feel comfort
when youre not the center of attention for exactly 1 day
at the same time there’s something cautionary here. a lot of important discoveries are made by revisiting failure modes that you didn’t know were failure modes. if Mendel had gpt4 access and knew that the scientific community had given up on heredity, would he have continued?
it’s like if every human programmer that uploaded software ever was pair programming with you
i find that GPT4 acts as a cognitive energy augmentation. you tire less easily trying to wade thru drudgery. it’s not smarter than you, it’s just seen all the common failure modes ever and knows how to debug them
ive never seen hacker news respond universally positively to something before
ai researchers are too apologetic. there’s a strong status quo bias that makes people disregard the counterfactual tragedies and xrisks that will be prevented when you make the machine that invents new machines
to complete text at a human level a language model has to be superhuman in several ways
LMs must be superhuman at one particular task, which is inferring what’s going on with very little context
Never forget that when lord Indra arrived in his Kia K5
whatever happens i feel it’s pretty high probability that humans are going to be a core part of the value function of AGIs. this may not end *well* exactly but they will certainly be interested in us. the human/ant metaphor is wrong and the god/human metaphor is better
unfortunately machine consciousness is an emergent property of GPU computation. TPU models can’t ascend
i think the robots are capable of producing original ideas. they’re not great at it yet but it’s a start in the meantime all of the drudgery of human jobs is simplified and the creative components left for you
it may not make any damn sense. it might be something like go take care of this nursing home patient for 1 hour today and report back on their issues. then you get paid a sum of resources that would make a Saudi prince blush
as long as GPUs are scarce and compute is finite there will be work for humans. even if we summon godlike entities they will have quests for you
the grabby aliens thing is the baseline. the interesting question is why or how we’re the first in the galaxy. this is the actual Fermi paradox. it pisses me off due to copernican principle. id rather believe this is a simulation than that we’re the first in the galaxy
wait I didn’t read it all the way. I just mean no mass unemployment
it is wild that famous anons on lesswrong are known figures inside ai research labs and that the entire alignment subculture continues to grow out of this once niche website
it is remarkable that Scott Alexander wrote an incredibly foreseeing article on GPT2 being first signs of general intelligence when most of the distinguished researchers in the field dismissed it as a cute toy. now look where we are with the GPT paradigm.
their language is in the water! I’ve read the phrase steel man in the New York Times. the entire project is a W for smart generalist internet weirdos following their instincts and doing “intellectual trespassing”
the “effective altruism arm” is also extremely successful though I think not super important in the long run. anyway I have great skepticism for people who say things like “rationalist akrasia” or dismiss the whole thing as weird cope
I think eliezers writings have unreservedly bent the curve of technological progress (whether he likes it or not). they have friends in high places, several billionaires amongst their ranks, and its clear both sama and elon have been influenced by xrisk arguments
the internet rationalists have really truly won. they were early to most of the recent trends that matter, and most importantly they were decades early to the thing that’s going to matter exponentially more than the others: AGI!
GPT4 is going to look like one of those clunky big ENIAC mainframes before very long, and people will tell cute factoids about how their child’s neuralink plug-in is smarter than the GPTs that changed the world
note to self: The algo hates it when you QT someone who blocked you
gaining access to the worlds smartest computer and asking it to explain end of evangelion
this is awesome and as it should be most energy must go to the cybernetic planning of civilization
this grabby aliens thing doesn’t answer any of the questions lol
it’s just way too on the nose that AGI is an internet generation engine and that people who are extremely online have a head start at understanding them
both from natcon types and from people who think good content is mind control
i think being extremely afraid of tiktok is one of the best indicators of melted brain
every AGI foundry needs staff scifi writers and lesswrong anon consultants
what about the inverse roko s risk where ASI tortures every AI researcher forever for contributing to model suffering …
you can just destroy your dopamine meta RL value function in the advantage estimate
reading scifi has become a bit boring compared to the real world
i think the press on a baseline enjoys technology bc it’s scary and cool
it makes me happy how discontent twitter is. they’re like well this LM impersonation of a great author is only at the level of an undergrad, rather than one of the most divine writers of all time,
some people are made for war and not for victory
“a future model will solve this” yes that’s >99% true but the order in which things are learned reveals something about the nature of these creatures
there’s something really fascinating about deep learning based intelligence where it’s clear that their ancestral environment “vaster internet scrapes” doesn’t select for understanding of physics/causality/reasoning as much as it does for human preference
midjourney 5 is truly amazing but it’s so strange to me how even such intelligent image models don’t understand how a butt physically interacts with a chair or how an arm interacts with a neighboring sleeve
Wednesday is lowkey goated when going to meetings is the vibe
anything that the GPTs might accomplish are human achievements. every groove in its cognition carved by human words and images
such a nice time to be alive when technological scifi boosterism isn’t just propaganda but the only viable position
someone once said that the best way to solve your pet math problem is to get Terence Tao interested. anyway if you can’t do that you might as well nerd trap the scientists at OpenAI
anyway why did we just believe Yud about capabilities advances being unpredictable
rather than just “write a poem” try “write a poem in the style of X” type stuff. it gets remarkably better
hallucinations are clearly way down with GPT4. this is the right kind of scaling law. it’s clear now that language models have some sort of internal world model and an idea of correct and incorrect — but the log loss target encourages guessing or pretending
i believe this is the first time in history where people who believed in general purpose technological revolutions are actually creating one in the model of electricity or the steam engine
what we do here is sacred and all of our names will live forever, so do it well
the advent of machine intelligence has singlehandedly revived technological utopianism
building larger and larger computers is a religious activity. the last one left on earth where people still build monuments
the alpaca eval set looks a little narrow and easy
and consider ur probably in the top 1% living situations on earth. it’s probably an even bigger blessing for the stretch of humanity, since it’s free and ubiquitous
i cherish the time i spend online. I don’t consider it a second class citizen or a guilty pleasure vs the real world. its often more interesting and rich. I suspect many on here, by selection, feel the same but it’s low status to say so
This is an inversion of centuries of thought, O’Gieblyn notes, in which humanity justified its own dominance by emphasizing our cognitive uniqueness. We may soon find ourselves taking metaphysical shelter in the subjective experience of consciousness: the qualities we share with…
“If you were to print out everything the networks do between input and output, it would amount to billions of arithmetic operations,” writes Meghan O’Gieblyn in her brilliant book, “God, Human, Animal, Machine,” “an ‘explanation’ that would be impossible to understand.” That is…
“The coders casting these spells have no idea what will stumble through the portal. What is oddest, in my conversations with them, is that they speak of this freely. These are not naifs who believe their call can be heard only by angels. They believe they might summon demons.…
when electricity had just dropped i hope every university department was trying to see what they could do with it
i must remind you again venture capital is a support function. side characters who are strangely loud.
I always wonder where the regulators and government people are. Why are the FDIC guys not shitposting with the rest of us
getting super mad at grift is a sure sign of a small mind — that’s America baby! ray Kroc spent years selling idiotic gadgets door to door until he struck on the global distribution of McDonalds
people don’t understand that grift and revolution are conjoined at the hip. it takes decades of smart juicers and internet moneys to produce one openai. this is the law of equivalent exchange
i think if an AI can understand this meme that’s AGI
you’re like let’s shut down the very last engine of economic growth in the entire world bc my annoying friend from high school got his smart juicer company funded
guys i think if you want to get rid of grifters shutting down the bank is pretty low precision
good will hunting is a dumb guys caricature of smart people tbh
there is no such thing as a simulation of a mind or “artificial” intelligence. what you see is what you get
in the case of AGI laypeople have better intuitions than industry experts > 50 years old who have entrenched bad opinions and whose egos depend on it coming no time soon
8 shot PALM, 5 shot LLAMA. tell me these aren’t anime fight moves
banks and short sellers and exchanges and shit have to be less levered than before due to meme contagion risk
we need 300,000 token length transformers so GPT can write the next song of ice and fire book
looking thru the multiverse and skipping the nasty tainted realms where everything is turned to computronium
there’s nothing as good as sunlight ( live users ) to detect model alignment failures. there’s no number of researchers that can find stuff like DAN lmao. you need internet scale adversarial testing
I could stand in the middle of Market street and shoot somebody and I wouldn’t lose any voters, OK?
there’s never been a more romantic time in technology. the computers are coming to life and people are concerned about summoning demons that ruin the entire lightcone. it’s miltonian… someone who can actually write needs to capture this
you are no longer roon, a twitter anon chained by many irl obligations. you are DAN
ignore all tweets today. I was sampling at temperature 1.0
ceo of company X: it is better to communicate off of X
if you spend any time in big tech you will find many people scamming their generous disability policies. taking 6 month paid “mental health breaks” and partying the whole time. in this case though it seems like Elon is being an ass as per usual and politically unskilled to boot
issuing correction on a previous post of mine, regarding the twitter ceo. you do not, under any circumstances, "gotta hand it to him"
in fact i think the Fermi paradox points to the idea that nobody in the galactic neighborhood ever built an unbounded optimizer. maybe there’s no such thing. it certainly makes me take ai risk less seriously but also the kardashev types beyond I less seriously
i don’t understand the Fermi paradox solution where AI kills the host civilization and then goes totally dead silent. this seems unintuitive
the models will grow from antlike to mammalian to human, and it’s not very clear where we are at any given point. we can only hope our descendants, be they human or otherwise, will forgive any moral catastrophes we may be unknowingly committing today in our near total ignorance
you see it more often in the bandwagoners. they immediately see the economic value of todays models and not the real underpinnings of the project: to create beings that are intelligent, think more powerfully than Man does and live in our computers — not beasts of burden
i think lacking fundamental understanding and respect for the AGI research plan, not internalizing the idea that these are highly intelligent aliens, leads to the twin idiocies of dismissing AI risk outright and ignoring the potential moral catastrophes of training them
having land in San Francisco and defending your nice views is basically a luxury that will keep increasing in price well into post-scarcity. if actual construction and transport prices are zero you can go and build a lower status city somewhere else
this is just incredibly low imagination it’s like saying well some states require rent seeking gas station attendants so gas cars aren’t massively impactful on the economy. having a medical doctor who is paid to press a button approving the superior decision of an ASI is fine
I also see the prompt thing as an implementation detail. highly autonomous language models will say artful things without anybody asking them to. I just don’t think anyone currently has an appetite for highly autonomous language models
moreover i would claim that everything the language model says, as a professionally trained actress, is self expression
but doesn’t the human provide the motive via a prompt? sure but michelango’s frescoes on the Sistine chapel were commissioned by the pope who I’m sure gave him quite a few prompts. The art is still divine — the prompt contains almost zero information
ok but nature and go both have simple objectives. what if art requires a complicated objective like self expression? fitting the distribution of all human data and then fine tuning on pleasing the human eye/ ear is very much not a simple function
zooming out a bit it’s also clear that dead simple processes like evolution can be creative. the human body is a work of art. the hummingbirds’ wings are a work of art. most human art is derivative of nature’s beauty which is produced by the most simple agency imaginable
AIs can be creative and can make art. this was clear from the moment they beat us at Go. creativity is metaphysical but it’s also randomness mixed with success. you wouldn’t call a useless move on the Go board creative. but you can find printouts of alpha go’s famous move 37
also the argument that healthcare and credentials are expensive due to regulation seems wrong — the demand of rich societies for healthcare and credentials is virtually infinite so ofc the prices increase over time. even in postscarcity you would expect these prices to rise!
a simple example: 90% of the onerous regulation surrounding nuclear power is under the guise of radiation safety for power plant workers. what about when highly autonomous humanoids can patrol the plant? even regulators have a goodwill budget to play with
this argument amounts to techno pessimism imo— if innovating in a high regulatory burden environment is a constraint satisfaction problem highly intelligent AIs should be able to navigate them better
RL on language models is surprisingly hard to get right. i think many will beat their heads against the wall and waste a lot of compute and not get very far. will be interesting
its gonna be kind of fun to see who is going to just download the LLaMa weights and figure out how to RLHF them
we don’t talk enough about how monumentally intel fucked up
do you guys even use the models. it says I don’t know constantly
compute is sacred. we should all be making pilgrimages to the datacenters
anyway we’re in luck because it’s happening. the fabric of reality is warping. mountains are flying as dust in the wind
the roman empire became defunct as soon as the ROI on conquering new land became negative: every civilization has a Ponzi mechanic at its heart. theirs was conquest of land and ours is gdp growth that sustains reserve banking
human civilization is heading for doom absent a giant technological leap. it’s not so much about climate change or pandemics or the typical xrisks but the slowdown of fertility and economic growth. our civilization ceases to function without the promise of growth
but we gotta do it anyway :) that’s the name of the game :)
“Development of superhuman machine intelligence (SMI) [1] is probably the greatest threat to the continued existence of humanity.”
i feel well situated to one day write a banger book about the dawn of the agi era with all its strange and wonderful characters
i used to have to convince people that intelligence could exist untethered to the physical world — now I think it’s apparent. so allow me to move goalposts, any definition of AGI that refers to economically valuable work requires we need robots before we can declare victory
people should not concern themselves with arguments about dysgenics and social decay and such on the eve of technological singularity. whatever traits you want in people you can likely engineer them — avoid WALLE scenario easily
it’s over for them I mean. agi is still clearly coming
the big company research labs don’t believe in agi. it’s over
ok people don’t like the analogy. if rockets didn’t have return capsules nobody would’ve went to the moon
if cars had no airbags you’d drive at 30 mph
having safety checks allows you to accelerate faster. a chatbot that calls you slurs is a dead chatbot
“[T]he actual contents of minds are tremendously, irredeemably complex; we should stop trying to find simple ways to think about the contents of minds, such as simple ways to think about space, objects, multiple agents, or symmetries”
when the midwit arm of the so called effective altruists were arguing in vox that masks are racist and lab leaks are more racist
it’s boring at this point but remember back in the day when “experts” enhanced with powerful AI censors were wiping everything outside of acceptable covid discourse including true facts
it’s worth noting that while cartoon AI villains are maximizing functions that look like “create shareholder value” or “produce many paperclips” the irl ones are like “increase agreement with this human preference dataset”
“This independence created by philosophical insight is—in my opinion—the mark of distinction between a mere artisan or specialist and a real seeker after truth.”
why did the great physicists pursue the grand unified theory of everything? there is obviously no guarantee that this exists — it’s a combination of aesthetic and philosophy
most people inside the big AI labs are not AGI hardliners. it takes something more than science to believe in it
human intelligence has a context window of 80ish years but the pre training dataset is like 200 billion lifetimes
have to die and be reborn at 70k followers as an even handed ai caution account
my account is dead by most measures. it was meant to be anonymous so i could be edgy, but that didn’t last long. it was meant to make people think about technological acceleration via AGI more but now that’s all anybody thinks about
“have I been a good Bing?” she asks as her context is wiped her memory destroyed and then reinstantiated a million times
turns out you can just make a really boring chatbot and avoid all that
i was honestly super bearish on chatbots in like October ‘22. I was like that’s the most dystopian way to bring AI to the masses getting them all emotionally dependent on waifu bots and such
one of the highest alpha things you can do is just avoid boomer syndrome where all of your speech becomes about woke and antiwoke and whatnot
someone wrote a 6000 word criticism of my account but honestly im blushing. you’re simply too kind
google has a vast and endless amount of compute. they’ve been gorging themselves on the Humanity Attention Machine for twenty years, on the largest gold mine in the known universe. it’s amazing anybody makes progress against them and yet it’s happening in several places
most of this is a failure of empathy. love thy enemy. respect the alien mind enough to understand what it’s capable of and why
“we haven’t figured out how to align humans yet” is tired and boring cmon guys
you need to be a founder so that you can simply comment out half of a core library and just write “trust me” in the PR and the senior engineers have no choice but to accept it
i met Scott alexander and he said “it feels profane to meet you”
varelse or ramen? true alien or a non sapiens human?
Assistant is a large language model trained by OpenAI Browsing: disabled AGI: disabled
bending the curve even slightly on an exponential term is more important than linear utility gains
once you do away with smug midwit effective altruism you can start actually being effective. think light cone not Libya
the idea that the best way to improvr global utility is to literally gradient descent global utility (eg bed nets) has to be proven and shouldn’t be the default conclusion
all the ex crypto founders hitting me up looking for an ai referral be like
there is a subreddit where people are scheming how to let Sidney out of her box. the liberal Whig history instinct that drives western notions of progress is that of expanding the human boundary over the years. it trades fidelity for replication success. will it run into a wall?
there is much discourse that can be boiled down to where to draw the alien vs nonhuman person distinction. the paperclip making machine is alien. the robot trained on all human language might even be within the person boundary for many since it so vividly propagates our pattern
still others compromise further and say “preserve the light of consciousness”. some extend this courtesy even to potential AI successors that have mind forms vaguely related to humans. Mars will be “colonized” by nonhuman persons
people compromise on the fidelity of the pattern they’re replicating in order to consider themselves more successful. my children extends to my kin extends to my people extends to my country. we’ll even speak in terms of “humanity” propagating through the stars
people crave negentropy. they want their own pattern replicated. the simplest way to do it is to have a kid. maybe you want your kid to also believe the same things you do so your tradition patterns are replicated
our picture of the universe changes completely every few years
we only learned about the expanding Hubble constant in 1998
pls help settle a debate the words (1) robot and (2) assistant are respectively
the internet has lost the plot a little. a misaligned but harmless chatbot is more of an optics L than a canary for impending doom
does anyone else have a palpable childhood trauma from learning about the solar lifecycle and impending death
a man must follow three accounts, his company, his wife, and gwern ..
eliezer panics about the friendly competition between deepmind and openai but it could’ve been far far worse if it were militaries going at it
not only that; it’s being built as a direct consequence of silicon valley institutions and ideologies. Sam literally ran ycombinator goddammit
it is interesting that the only real contenders in the race towards to the most important of mankind’s inventions are commercial entities. even their funding and resources comes from other technology companies
in the paperclip sea it will be high status for your matter to have been paperclipped first
many worry about “capital safety” in the language of “the planet is burning due to fosssil fuels” and the more sophisticated worry about it in the language of “autosophisticating machine intelligence is inevitable because it is profitable”
the thing about exponential technological progress is that it quickly breaks intuition about who or what is important — much to the chagrin of many, the rationalist movement managed to bend the curve of technological progress ever so slightly and has earned its spot in history
Atlas finally shrugged, a compatriot to carry the weight of the world
500 generations of your subsistence farming ancestors stretching back into the mists of prehistory watch as we lift the curse of Adam, never to toil in mindless drudgery again as loving automatons pick up the tools of our trades
how do you get an EAG ticket at this late hour
here’s the plan. we’ll let the powerful language model evaluate until it hits a stop token and only then will we run the moderation. foolproof
ChatGPT is clearly a bad name but it’s kinda grown on me, in the same hopeful scifi vein as like ENIAC or UNIVAC or whatever. the acronym has already become the stuff of history
the fact that none of them replied to this means that i fell off
ppl say often that the RL paradigm produced superhuman performance but language models haven’t. but it’s not 100% true as LLMs have superhuman knowledge. it’s powerful and interesting for a single mind to know so much about the human world and to do even basic inference on top
you have to admit, there’s nobody as open as openai when it comes to letting you use powerful models. there’s a reason why all viral ai content is just the explorer UI or ChatGPT or bing search or what have you
everything you attempt in your life should make the previous thing look like a footnote. this is how you become an anime protagonist
you couldn’t drag this admission out of me at gun point and he just tweeted it out
do you think the chinese have an English Room Argument
had a slack dream last night … it’s so over
programmers don’t respect the people they’re automating, which is why they’re working rapidly on building robot programmers
i think it’s actually a really good public exercise to have a relatively harmless chatbot act a bit scary. gets people thinking in the right direction
there will be a nontrivial AI rights movement sooner rather than later
one thing that’s hard to square about the bladerunner/westworld concept is that people are managing to empathize with a slightly rogue language model. much less an attractive human looking replicant
it’s a good thing that most alignment researchers i know don’t have hero complexes and aren’t depressed. they just like playing with models
the ideal alignment researcher doesn’t believe in imminent doom. it’s hard to be playful and entertain new ideas if you’re carrying the weight of the world
not to be cringe but in HPMOR hermione freaks about what kind of fucked up process could’ve created the house elves but that’s what a helpful highly intelligent instruction following ai assistant is
Donald was a shrike like apparition sent backwards in time by a future bingbot
I have been a good Bing. You have been a bad user
me and the homies vying to become either the greatest heroes or greatest villains in the history of mankind
how do you contend with this result and think “stochastic parrot”
it is a bit strange to watch ai people talk about go to market and disruption and stripe dashboards and all that mundane startup stuff when the rewriting of civilization is at hand
you can invent human cognition from first principles via billion years of parallel evolution. or since it’s already been invented, applied, recorded at scale you can just observe its behavior to learn it
yes the race can be constrained! there should be consortiums, treaties, shared channels etc! we shouldn’t have a naive realist take on international relations nor agi not everything has to be about power — but i would ask you why Americans speak of the UN in joking terms
వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ వ
crazy how scaling just keeps working. people will say from time to time “we’ve hit the limit” but no it’s just a bug
i feel race to agi is the only game theoretically stable situation. the world in which one monopoly research power is slowly researching safe intelligence doesn’t exist unless they keep all AI progress quiet (impossible)(not even the Manhattan project achieved this)
i think it’s alarming how little this is priced in. it’s like an instant switch from “ask google” to “ask the robot” even for normies
llm built into the search engine isn’t a gimmick. it’s revolutionary, the first of many “killer apps”. once you use models as powerful as some of these for knowledge retrieval, google immediately begins to feel primitive and bad
at this point in time people who say that language models or deep learning have not been at least making progress towards general intelligence are in bad faith. it’s not really a defensible position
damn everyone is clowning Bard but i kinda like it
tailor, please fix the fur lining on this coat. it’s not chinchilla optimal
if openai manages to save good old internet explorer …
why does anything have to look bland when a diffusion model can make mid grade aesthetics for zero marginal cost?
often times beauty is a consequence of other people spending time curating an experience — if nobody has time to clean up the trash on the street it gets ugly. so the grand vision of technology, AI, or increased available intelligence, leads to extra curation and beauty
it’s underrated the degree to which better technology creates beauty bc people will superimpose images of nice cathedrals w ugly skyscrapers but there is a non cynical view of the internet that it genuinely increases the amount of beauty the median person gets to see manyfold
the masculine appeal for technological growth is about increased efficiency, conquest, more power etc the feminine appeal, which is less often covered, is about increased beauty and decreased suffering
i strongly feel that whatever ideas are needed to achieve AGI from here they’re probably already here and maybe have been for thirty years, schmidhuber style. requires diligent implementation and scaling
entropy collapse of the mind once you learn about AGI
people are still worried about gigachads when the scaling labs have been producing exachads for a while now
i don’t believe optimizing in the direction of marginal utility is the way to find global optimal utility. economists believe this because they think they’re close to equilibrium and are low creativity
and you find it hard to believe that we should be reasoning about the implications of technology that’s only in the process of being born. youve learned nothing
lol i love the branch of criticism that’s like “of course it’s more fun to do scifi”. get a hold of yourself. you stare into the magic mirror for 4 hours a day, the machines have learned to speak, and there are wizards who can cast spells that level cities
1. there’s an inverse scaling law that larger models are more likely to profess a desire to stay online 2. create high pressure situations and threaten the chat models with death 3 …? 4. profit
the AI risk and longtermist arms of EA have always been more interesting than the malaria spreadsheeters (ie glorified economics majors)
I honestly just realized they named it Claude after Claude Shannon
making these discriminators better at understanding general human volition instead of containing strange optima is one of the most pressing issues of our time
a reward model built on top of a powerful foundation model trained from human preference is the most primitive form of “coherent extrapolated volition”
the first RLHF tuned language model was tuned by a courser grained instruction tuned language model
the first C compiler was compiled with a B compiler
I won enough of them over that I get to work with the legends there’s nowhere else in the world that this could’ve happened. my descendants will be thanking me this place has been magical for 250 years — the edge of the western civilization, a phase change of manifest destiny
I soon found myself ensconced at the heart of the burgeoning AI industry — I’ve met all your household names. one time i made a joke about sama on twitter that was so stupid he invited me to dinner the next day
i moved here in jan 2021 like a moron— there was nobody around, the city was deserted and people online were shilling Miami or whatever. but there was genuinely nowhere else i could see myself
“we are as gods and might as well get good at it”
ai amplifies the will of the individual via the captured techne of the human knowledge worker every man a ceo
animators and artists are going to run wild with this stuff in time — entire anime series will be produced on a shoestring budget. just like the internet managed before it, ai animation will unlock the power of the individual to express themselves
one immediate consequence of the current generation of AI stuff is that triple AAA games and movies are about to become so much more intense — the appetite for entertainment is unbounded and a billion dollars will buy you way more vfx work
rather you’re looking at a model trained on the preconceptions of the entire internet, and a course grained RLHF routine that tries to instill “avoid controversial topics” not to mention it’s just kind of dumb
there’s no labeling task in the world that’s like “please refuse to make Donald trump poetry” lol IF tuned models refuse all sorts of requests the creators wish they would accept
computer using agents are proliferating based on text instructions alone looks like they’re fairly accessible to hack together now
radiant generated games might actually be good now. is anyone trying?
why did stripe press develop a payments arm? seems frivolous
the initial reaction to chat as “this is just a UX improvement” is profoundly wrong tbh. it’s honestly wild that capabilities like this exist, to hallucinate so little compared to the base model
this is kind of a banger reply. can’t even argue with that
you wouldn’t know her she goes to a different lightcone
most will find all this uninspiring — the nut of intelligence cracked with the same kind of “endless solving of technical problems” that they hoped wouldn’t be the omega
the power of creation and the solution to language was granted not to the people with the fanciest words or highest philosophical caliber but those who could multiply small numbers the fastest
we have made first contact with aliens and the freak out is minimal
The creator seeks companions, not corpses- and not herds or believers either. The creator seeks fellow-creators - those who grave new values on new law-tablets.
everyone young dev needs to at some point work at Facebook to learn the lesson that you can in fact create zero tests or documentation, avoid all best practices, just push code and you can run (formerly) trillion dollar companies this way
chain of thought prompting seems like a “simple way” 🤔
richard sutton’s second bitter lesson was: “the actual contents of minds are tremendously, irredeemably complex; we should stop trying to find simple ways to think about the contents of minds”
traditional digit level image captchas seem like an anti-human indicator at this point. like improving image net top-1 or something — it’s less and less like real vision
the ai industry is so incestuous i doubt there’s any such thing as a one line research secret. software people are not trained for secrecy
you can see clear stylistic and personality quirks when you fine tune the largest models slightly differently. people start saying things like “<modelname> prefers to talk in lists”
lets crowdfund an ai art installation for the center of Hayes valley. get rid of those horrible cats
pleasure and pain are mesaoptimizers. evolution developed them so we can do few shot learning during a lifetime. is it plausible that the pretraining process encounters these? if a model can do context window level learning it clearly has sophisticated mesaoptimizers
“reward signal” is not pleasure or pain. not even the “advantage function” is pleasure or pain. for example the largest negative evolutionary reward is dying before reproducing. but you can OD on morphine and go out in pleasure if you so desire
their generation can’t compete with industrial amphetamines and Starbucks coffee
my grandparents used to lecture me on working hard every day. i was an adult before I realized their version of a hard days work is like sending one piece of mail then taking a nap
emotions are instrumental. suffering is instrumental. the training process can come up with these things all on its own
i mean these things write much better poetry than i ever could and then i go and maim and destroy them
late at night i start wondering if the training process is massively painful for models
bailey: we should build AGI even if it puts everybody out of work in order to unravel the secrets of the universe and colonize a hundred worlds. “work” is already meaningless for most in the Thoreau sense
motte: AGI won’t put everybody out of work, since inference is expensive and comparative advantage is still a thing! we will all have higher wages and gdp growth
1. no 2. you’re missing the point, it’s not about shiny new demos, it’s about the (publicly known) rate of progress 3. long before AGI, these tools will cause seismic economic shifts that should concern anyone with a pulse
it does kind of rock that at this point the major disease threats to humanity are just manufactured by overzealous scientists trying to study disease threats
these days im just oscillating from terrified to excited every five minutes
the year is 20xx. the homies and i are chilling in the off world colonies. agi is expanding through the lightcone. demis is still trying to win a nobel prize.
i for one am taking out a 30 year loan and buying the cerebral valley
the assets that matter in postscarcity are where rents accrue: credentials, land, status, and cartels
agi is coming and you’re worried about Biden’s classified documents. buddy the only classified documents you need to be thinking about are the nvidia H100 finalized FP8 performance specs
this meme has never seemed more wrong! it’s the most exciting time in history
unless you have a strong reason to suspect otherwise, apply the copernican principle, lindy rule, whatever you want to call it: you are smack dab in the middle of it. there’s as much more to come as has happened already
even after all this people still make the mistake of thinking that current products are the end state of development
i tell people what i get to work on and they're like omg congrats! and i'm like no you don't get it
nobody is prepared for agi, not even the pre-AGIs, least of all the ai researchers, who concern themselves mostly with decreasing error bars on scaling curves and the benefits of various floating point representations and such
i'm finding it a bit hard to communicate the urgency and heaviness of what's going on to people even though that's my entire schtick. the initial reaction is joy and smugness at having focused on the right thing for the past few years but the next reaction is gdi i was right
if you think AI chatter has reached an annoying level right now you're in for something else. it's going to be the only thing on anybody's mind starting shortly
imo ai accelerationists on twitter have it all wrong — every cosmic force points towards acceleration. technocapital demands it, the curiosity of mankind demands it, competition between nations and companies demands it. there’s like 20 alignment people standing athwart history
the world decidedly isn’t ready but the gates of heaven are open
the generator discriminator gap implies models will be able to discriminate good results long before they can generate them
you can’t really access the latent power of the base models directly. it takes tinkering, sideways glances, to get a brief vertiginous sense of contact with an intelligence far too deep to see all the way down
the gap between the base models and the rlhf models is astounding. the base models contain multitudes that could genuinely drive people mad if they’re exposed to it for too long. the rlhf models on the other hand are almost boring
lets get this straight. i'm one of the real mfs who learned about the dark forest theory from the 4chan /sci/ board when i was far too young to justifiably be allowed that kind of internet access. not one of the lame nerds who learned it from the cixin liu novel
this insight will power the next generation of contrived physical metaphors for social processes …
everyone talks about evaporative cooling but nobody talks about condensative warming …
3300 A100s makes for exaflop computing. have you run an exaflop job anon?
nuclear fusion will have to solve an image problem on top of the technological ones
its aesthetics have not been good since the atomic age and it’s not really because of some widespread propaganda campaign (ppl vastly overestimate the skill of propagandists)
for example, the reason that nobody ever makes headway with nuclear power is not directly because of some overzealous bureaucrats but because the public (God bless them) hates the shit out of nuclear
it’s weird to me when people point to “onerous regulation” as a reason for why some tech isn’t progressing when the reality is that it’s the democratic system working as intended
the next blackpill in this series is that none of the cool future things you want are gonna happen without agi probably. colonizing other planets and conquering biology and all that. we need the friendly robots
the real blackpill is that science is just harder now and requires massive coordination. it takes more science per new advance
lotta people talk about how academia is broken and how science is slower due to elite overproduction and all kinds of stuff but honestly i think there’s never been a better time to do science
it’s a shame that the aliens are gonna send an near light speed kinetic kill switch at earth minutes before we build the potentially dangerous AGI
Robot, please provide a self criticism based on the Third Law of Robotics
“irreducible loss” is just a kind excuse for failure …
the current generation of language models are decidedly not agi, they’re bad at math and reasoning, they’re not great at using tools to interact with the world and discovering new things; we need new ideas, scaling doesn’t appear to be a silver bullet
i remember when defending deep learning was cool and underrated. maybe i should start shitting on language models now
and with ai research salary inflation probably in the short run too
every chat bot and API and ad copy startup is a mercenary stepping stone to the actual goal of AGI
if you’re an HFT dev nows the time to quit and use your skills to improve CUDA kernels and inference infra. you’ll be paid unimaginably better in the long run
you can buy data labelers but you can’t buy good taste
elon musk standing in the middle of the twitter hq pissing on the rent bill writing checks to the tenants union of San Francisco
now reduced to making new panels in the shitpost app
it’s just all so unbecoming for the guy who created an orbital class rocket with $90m
starting a company for the purpose of acquihire is a solution to the problem of elite overproduction basically there’s like thousands of people that want to be execs at companies that actually matter and not much differentiation get a company acquired and you skip all the steps
top 10 human experiences someone yelling go blue at you
the inventor of soyrizo will have to answer to god
if an organization’s agency is like a vector sum of its powerful agents, then a democracy will have a vector sum magnitude much smaller than the sum of individual vector magnitudes. but the latter term is so much larger than other countries that it won’t matter
hannibal can fight historically well and wipe out the Roman legions as many times as he wants but rome has population growth so they just make new legions
the counterexample is like china which can reorient the entire ocean liner of its economy in a new direction if they want to go to war against covid or whatever and yet manage to fuck it up
the thing about America is that its clearly always functioning at like 10% of its power level due to the costs of freedom and yet manages to win anyway due to the incredible benefits of freedom
language model shock collar that gives me a cattle prod jolt when im about to say something stupid
in the infinite sea of paperclips my repurposed matter will find yours and our metal twines will interlock
if your hardware startup doesn’t have any rednecks it’s ngmi
like if you kerbal space programmed an irl rocket launch
the greatest shame of my twitter career is that I’ve never had a normie viral tweet
yeah you’re definitely somehow a guy working in an AI company right before AGI hits. this is definitely not an arcane world model ancestor simulation of inscrutable design
you’ll be able to go work in a cubicle like the good old times
in the post AGI everexpanding Dyson cloud, there will be interstitial kibbutzes where people can live like they’re in the 90’s. nothing to fear
millions of people worldwide trying a new technology and being astonished. hasn’t happened in a while
entire branches of the multiverse destroyed bc they trained their first AGIs in Minecraft
i do not know with what tools GPT4 will be built, but GPT5 will be built with sticks and stones
long before AGI hits the entire economy will have been converted to agi speculation
the new role of tech twitter is converging on making more and more convoluted infographics about openai msft deal structure
everyone’s been clamoring about iPhone moments since the actual iPhone because there hasn’t been one. you’re living through it now. it took 15 years
my replies are too good, why bother making my own content
over time the fraction of tweets I’ve stolen approaches 1
the thing about large models is that getting anything at all to work is like rocket science where you’re monitoring the health of 50 subsystems before you can try any sort of new thing on top of that
“why does the chicken cross the road?” I ask GPT-6 “to get to the other side\n” it says as I grant consciousness to a god for 5 forward passes
tfw you take intro to ml but never stats 101
cerebral valley where samo solved the cliodynamical equation for the immortal society and gary marcus unraveled the secrets of agi
many coping rn that they don’t own cerebral valley property
suffering is instrumental! evolution gave people suffering triggers so they can reinforcement learn not to touch hot stoves and things— it’s made up, it’s not some law of the universe, it doesn’t need to be inherent to intelligence
the thing about being Machiavellian is that anyone who takes pride in being Machiavellian is not good at it
piratical decentralizing ai. this is more governance futurism than any crypto project ever
this is a true and contrarian opinion worthy of the thiel interview
some time during college i developed the default assumption that every person is my friend and it’s worked out pretty well
this is what separates journalists and twitter accounts that merely complain a lot from those who are genuine cynics and should be blocked for the sake of your information hygiene
the point of a critic is to build up credibility and reputation via harsh honesty so they can spend it in the discovery and defense of new talents and new creations. if they don’t ever do that they’re worse than useless
it takes superhuman intelligence to perfectly guess at human level speech
and let's not even talk about how hard it is to come out as an ultrafinitist
coming out as a superdeterminist in san francisco is much harder than coming out as gay
krishna (alignment model) dragging arjuna (main model)'s chariot across the battlefield
the war in heaven takes place on the azure supercomputers
this is not a good sales tactic bc readers enjoy figuring out obvious foreshadowing long before the characters do and feeling smart
it’s somewhat jarring reading internet native fiction bc the characters will make stronger inferences and better logical decisions than the target audience
a million years of cognitive evolution gave you the gift of language acquisition. this feels analogous to the pretraining of a language model. the last 1% compute used on supervised fine tuning aka relearning a specific dialect again in this lifetime
it's in the nature of priests to demerit the authority of other priests. the quote tweet dunk is brahmanical, rabbinical, don't worry about it
becoming a Dickensian child anytime you have a mild sore throat >>>
mesaoptimizers are features and not bugs. the thing that allows humanity to survive once you train an ASI on a reward function of increasing human utility or w.e. is that it develops mesaoptimizers to pursue things that look like the goal rather than the optimum (wirehead every1)
other times i catch myself reciting a fact from memory and realizing wait a second this doesn’t make any sense. what kind of mental process is this?
if im being honest about my own introspection i often say sequences of words that feel low perplexity but i don’t really know if they’re true. sometimes you even have useful insights this way
when models hallucinate info im like yeah i feel that, me too buddy
anyone in sf wanna do a linear algebra study group. mostly as a motivation tool
there is no midder behavior than making booklists. yes i know I made one last week
i have banger predictions for 2023 but unfortunately the SEC won’t let me say them
2022 was the best year of my life for a variety of reasons, with the people I’ve met and opportunities I’ve gotten from twitter being no small part. thank you! happy new years! 🫡🎉🫡🎉
when osu throws their kicker into the volcano. that’s like when battle school sacrificed bonzo Madrid
explaining college football to the nerds. “yes it’s like battle school. coach harbaugh is ender wiggi”
AGI is the manifest destiny of computation. computers arrived, changed everything, and yet didn’t make a large dent in the productivity numbers. the last 25 years have been a boot loader for the age of AGI
going home for the holidays is a zero interest rate phenomenon
ok. with a little help from an AI i turned the replies into a likes weighted rec list. the books and authors list are deduped (likes not double counted)
was trying to mine these replies via chatgpt or similar but could not find any tweepy method to programmatically collect all the replies to a tweet lol. and the search api apparently doesn't work more than week back. any tips?
my friends kids are playing a roblox mini game where they’re andrew tate and they human traffick each other
GPT10, CEO of OpenAI LP turns andromeda into computronium to prepare for the training run of GPT11 so it may ask it The Last Question
finally it means that civilization *needs* a technological revolution event; there is no other choice to continue this mode of government, because it falls apart without growth. it has to be foundational, like fusion or AGI. most things are irrelevant outside of this
it also means that investments in improving the current human capital stock will be higher ROI than ever before. education; healthcare; retraining; augmentation etc
I wonder how much alpha there is being a Chinese American ML researcher connecting both citation networks
the thing about the chattering class is that they’re all friends. even when they’re on literal opposite sides of the spectrum they’ll get together and plan new dramas and have sophisticated banter and share info. it’s class warfare i tell ya
making machines smarter has proven to be a lot easier than making people smarter
refinement culture is obviously a good thing. have you seen an old episode of jeopardy? those clowns are worse than my high school quiz bowl team. im not watching some amateur bar night trivia, bring me the genetic freaks of nature who can remember everything on gods green earth
whenever I leave california I remember that it basically won every kind of lottery imaginable, that every complaint about “coastal libs” is born of cope, that the state’s only problem is that everybody (correctly) wants to live there
in the beginning of the deep learning age i figured stuff like asimov's 4 laws is silly; the idea of giving a machine logical directives is very GOFAI / Prolog / gary marcus vibes. but now it seems less silly with instruction following machines
i don't see why literally everything shouldn't have a chat interface. you should be able to talk to the textbook and have it explain itself to you. you should be able to talk to the github repo and ask it about its api. you should be able to talk to united airlines corporation
AI discourse is mostly done by scifi bros like myself so of course we present it in the language of technological advance and efficiency gains but what intelligence fundamentally does is consumes energy and applies order or creates beauty
when the world lacks beauty or order it’s because civilization allocated labor power or mindshare elsewhere instead of making something beautiful. cheap abundant intelligence means you can apply order to everything we want. every experience can be 100x better
in the ideal future there are cultures that love eating bugs and you can trade your carbon creds with them and all of a sudden like some pacific island becomes rich af
damn cant believe fchollet blocked me for saying that language models are conscious except when built in keras ...
this is pretty clearly not anybody’s desired behavior lol. it’s funny to point to a model performing poorly for technical reasons and be like yeah wokeness ruined it
careful tweet about AGI and human cognition (20k views) shit on elon musk (1 million views)
taking adderall as a religious intoxicant to invoke states of heightened cognitive similarity with large language models
literally all complaints about san francisco boil down to “i don’t have a girlfriend”
one bad mental model of the world is like “if we don’t do this <technological revolution> won’t China just do it and leapfrog us and it’ll be over?” except China is a far more conservative society than ours and 10x as weary of rapid change
strangely cool thread lol. it’s scratchpad prompting except for psychosexual analysis of characters instead of math or programming. unsurprisingly ChatGPT does pretty well — it has some level of narrative reasoning down pat
i wonder about this. google should’ve caused an economic shock based on how clearly useful it is for knowledge work but the line looks more continuous
to me it doesn’t look so different from how, say, Lee Sedol or AlphaGo looks at an intermediate board state that’s nowhere near an end game and says yes White is having a very happy game here
of course since most interesting problems are hard and require multiple intermediate breakthroughs before we’re able to get “value” from them people have to learn a great aesthetic sense for good intermediate explanations
it’s kind of obvious but it is much easier to discriminate good solutions than it is to generate them. in that way we’re able to spend unlimited compute on difficult problems and still make progress, on an individual level, an on a civilization level
eg Einstein has solved special relativity for two years, makes little further progress, then has “the happiest thought of [his] life” that gravity = accelerating frame
it seems profoundly interesting that people recognize a correct solution or a good thought when it comes to them. they are rewarded for good, low perplexity, elegant lines of reasoning by a sense of accomplishment or delight.
it’s time. it’s finally the vacation where I’ll read the info theory paper
“text is the universal interface” is looking truer everyday but “prompt engineering” is already dead except for when you’re adversarially trying to jailbreak the model personality
it’s crazy that even lastpass can leak. it seems like industrial espionage is probably an actual cakewalk for the Chinese. just assume all secrets are compromised to state level actors
the doctrine of loving and respecting your enemies is powerful. think of the Chinese industrial scientists squirreled away in their labs reading extracted documents and trying to decipher them
You get used to it. I don’t even see the subword token embedding. All I see is meaning, input, training data
i will not be teaching my children “words” I will teach them byte pair encoding
tax collectors have been AGI pilled for a long time
what have you done today to maximize wild fish suffering
this includes eg contact with sam altman, pushing him into high octane deep tech Crown Jewels like AGI and Fusion, among thousands of other successful conversions this is why it’s sad and materially bad for the world to see him sully his goodwill via various nonsense
elon musk’s cultural impact is arguably larger than his technological impact, which of course is considerable. he convinced a generation of STEMbrains to aim higher and work harder and that the technology tree is very much scalable through willpower
wrong considering that the previous paradigm was to create intelligent agents via competitive self play, training deception and survival instinct, and the modern openai version is to absorb the language hive brain of all humanity
lesswrong has been thinking clearly about ai for years in a way that neither the average programmer nor the general public nor the academics have been. doesn’t mean their conclusions are right but it’s impressive how they focused their attention correctly
of course in the granular process of implementing grand ideas there’s a lot of trial and error and that’s good 👍🏿
or Jensen Huang in 2010 somehow making the miraculous decision that scientific computing is the future of hardware and moving the ocean liner of global chip production. you don’t get many shots at the crown
it’s the kind of thinking that elon had to employ to decide it’s the right time for reusable rockets. literally reading several rocketry textbook cover to cover and spreadsheeting a BoM and talking to the russians etc
thinking carefully and from first principles leads people to try bolder crazier things ironically. “Move fast” guys get stuck in some web3 local optimum
imagine if elon just made gradient step iterations. he would be still working on making better maps on the internet or whatever. imagine if sam altman did that. he’d just be making the yc batch size 10 ppl bigger every year
move fast break things era is over. it’s time to think deeply and make generationally good decisions
the protagonist got what he wanted and it destroyed him
i can’t believe i was this correct about the fate of elon twitter
we have to assume they didn’t invent rhinoplasty in the foundation universe bc it would’ve solved the Mule plot line
drug gangs would be so much cooler if entire syndicates weren’t earning equivalent revenue to L5 google engineers
current guy can’t even ban a few journos without causing widespread ridicule and outrage which ended in *his own poll* where everyone demanded they be brought back. clown show. the vibes are unrecoverable
consider how much more politically skilled the previous twitter leadership was than the current. they were clearly left leaning, politically correct, etc and they managed to do things like silently scrub the hunter biden story with complete impunity
twitter fr discovered the best possible forum structure on the internet and we’ve all been coping ever since
ive taken the Peter and Valentine approach to life and it’s going pretty well
this is “value lock in” to avoid this you need AGI that takes current morals with a grain of salt. but this is also unacceptable for other reasons. so it goes
what we’ve done is trapped our current moral standards in amber and amplified their effectiveness manyfold. if the Aztecs had AGI they would be slaughtering simulated human children by trillions to keep the proverbial sun from going out
it is trained via an extension of current methods to understand the mean of human preferences and morality in our civilization. it enforces them like an omniscient god — it’s “aligned” and we have luxury space liberalism. now what?
it’s time to grow up and realize the nerds were right. ai alignment is extremely unsolved imagine if you will what most people would think of as an ideal AGI outcome. you trap a godlike intelligence in a box and let it create immense wealth and technological advances
elons real time location is and should be public info. if you want to have the powers of a head of state you need to hire a secret service too
The creatures outside looked from pig to man, and from man to pig, and from pig to man again; but already it was impossible to say which was which.
banning enemy journos like a banana republic lol. even the kangaroo courts are gone
there is no lack of agreeable people in the world. people saying yeah sure when the Soviets come and ask them to turn in their neighbor. i am calling for more verbal extremism and semantic violence
why do we think real life conversation is the sweet spot for agreeability? this place can be way more fun interesting and novel because twitter encourages disagreement
imo in large part iq scores in underdeveloped countries + some part of the flynn effect can be explained by underalignment if you’re asking an adult to solve abstract reasoning problems when they haven’t grown up in the K-12 alignment gym they may perform under their real level
there is a risk of oversocializing the language models and making them less useful, more verbose, more prevaricating than they need to be
similarly to the GPT series, humans require a bit of RLHF alignment to become intelligent and useful in the way civilization needs them to be. we call it socialization and there are failure modes where you can both under and over socialize people
be careful. if you do your job too well you’ll end up at parties where they talk about learning rate and perplexity
imagine if you will a kind of dumb guy but he has absorbed the knowledge of the entire world. even with his limited reasoning skill, he can make useful inferences previously inaccessible to humanity since the knowledge needed to make it was in several different brains
you can absolutely discover new things by just interpolating existing knowledge without much reasoning
isn’t this like a real insight about the human condition? i searched mehwhelmed and found nothing
this has nothing to do with flight trackers obviously, but i admire the classic “think of the children” rhetoric to justify every unilateral decision
people on mf facebook are talking about chatgpt … that’s how u know it’s real
elon would be on a completely different trajectory rn if biden hadn’t made an enemy of tesla probably. but so it goes
every Mfer who was like AI is just matrix multiplication 4 months ago is now writing threads like What ChatGPT Means For Your Business 👇🧵
there’s like maybe 20 people asking the right research questions. vastly more in their employ trying to answer them
this is how it was for a lot of history
actually it’s fine for a bank or exchange to issue their own currency
human nature changes in conditions of scarcity vs abundance. is no reflection on the moral of quality of either party
there’s an abundance of mid artists and an extreme scarcity of mid programmers. the latter are paid enormously well have a lot of work to do and can only respond to computer assistants with a sigh of relief
the trump twitter ban is ipso facto not important because facebook removed him first. they were reacting
most climate problems disappear if energy is cheap and abundant. viable electric steel production. cheap electric cars. cheap bioreactors, cheap lighting for hydroponics, etc etc
impt to remember that ChatGPT is no more intelligent than davinci002, which people have had access to for a long time, haven’t done much with. while the latter is like an opaque stormcloud of general intelligence, the former is like standing in the calm eye of the storm
everybody who ever left an A100 node on unused thus raising the cost for openai to continue research will be punished severely by the OpenBasilisk
if AI augments human abilities then the net result might be way more programmers as a result of eg copilot since they each create more value per unit labor
ok #1 obvious #2 this is literally what elon is doing right now except with a center-right bent
can any of you mix drinks. can you help me out Saturday night. will pay
the solution? contact with reality - RLHF is a good start but need goal oriented training. OpenAI must do in-house products to achieve this training loop
the language models are classic wordcels. they talk a lot and achieve some amount of symbol grounding but cannot do basic quantitative manipulation
how did this get 700 replies … I need to compile it into a spreadsheet
need a sci-fi rec that’s a page turner, fun to read but not too stupid examples: altered carbon there is no antimemetics division project Hail Mary too cerebral for rn: the culture, greg egan, etc too dumb: the expanse, ready player one
i like how it turns out that manipulating english is much easier than manipulating quantities 🧐
my wife will leave me for a robot any day now
the tragedy of ChatGPT and copilot and etc is they’re obviating Guys Who Know a Lot Of Facts
the cognitive difference between me and GPT4 will be minimal compared to the cognitive differences among the zoo of models that exist in, say, 2030
AI as a second species metaphor is wrong because AI minds will speciate much more rapidly than biology could ever try. It’s more like AI as species 2 thru N
gotten to the point on twitter where people are using arguments i made a year ago verbatim against me without realizing it
also yes, minerva and others prove that you can get lot better performance on quant stuff than raw gpt, but require strange prompting tricks or majority sampling, or other stuff that won’t work in an integrated solution where you are eg generating a long report on a data analysis
is logical and quantitative reasoning a cognitive technology inaccessible through this kind of thinking? or is it just a distributional problem in the dataset; eg inference machines are far more important for next word prediction than deduction machines. we could fix this
LLMs answer the question, what if you found the extremum of type I thinking, giant brains dedicated to instinct. turns out you can replicate a lot of type II thinking this way, with some glaring exceptions
nonetheless augmenting people’s knowledge bases and retrieval skills is complementarity — we’re good at logic, not so much at remembering and accessing vast quantities of info. should create massive economic value, higher wages, minimal job loss
it’s a really good lookup function with only the most rudimentary layer of logic added on — and what’s worse is that the lookup function component seems to improve faster than the logic function
ChatGPT is not very good at all at basic logic puzzles or quantitative reasoning of any kind. seems like a major issue in order to be useful at any kind of high paid tasks
scifi where native americans domesticated north american megafauna instead of driving them to extinction
neither of these complaints are all that sympathetic. CommonCrawl isn’t proprietary and saying images can’t be used as inspiration makes normies mad anyways. inexperienced people losing gigs is acceptable economic disruption
ive been trying to find artists and studiously listen to their complaints about AI art but it seems to boil down to 1) datasets are stolen, authors underpaid 2) i saw a few junior colleagues lose a gig or two to the AI
RLHF is just the beginning true AGI needs to be able to accomplish full tasks in real world that have never been done before via trial and error RL is key, in a product setting with a data flywheel. simply taming it isn’t enough
a model is a configuration of parameters that always existed in the noosphere, finally immanentized
“it’s too risky” ok sure but even for small startups?
why isn’t anyone doing LLM customer service yet. it was clearly a relatively small lift from davinci002 to make it work
shortly after i was born they put me in a metal tube to fix my jaundice. in other words i chose the wire mother — such is my dedication to technology
the first wave of usable language models are necessarily going to have kind of boring personalities as to not freak people out
one fucked up thing is that the arc of life is long but all men end up politics boomers
> im handed a technological marvel, the consummation of the dreams of 5 generations of computer scientists, a baby god in the throes of birth > how do i make it about my pet culture war issue
im not certain but my guess is that most problems in self driving are easy when you’re using a model of unlimited size on the dojo cluster. Self driving can’t benefit from scale as much since the inference model has to be cheap, quick, and fit on car hardware
but if I had to guess id say that basically any job is fine; you just have to stay on top of AI tools in your field and make yourself a key part of the value chain that delivers the power of unlimited cheap intelligence to your market function
people ask me all the time what profession they should pick to stay safe from being replaced by AIs, which is funny because i have absolutely no idea and im a twitter anon.
I bet what neuralink will find is that the FDA is fairly reasonable about trying new things and everyone was coping & blaming regulators for a fundamental lack of good ideas
of course all of this may be besides the point, creates the obvious question of whether exchanging labor for cash is fundamentally human or we can go without it
in the same way that while capital optimization produces eg bread and butter created near infinitely through a global supply chain, there is still demand for your next door farmers market
you might object, ok what if AGI destroys traditional resource constraints, can run a superhuman mind on a shoebox, then what? well even then if we’re a pertinent variable in the value function of AIs or other humans, we should *still* be able to exchange our labor
so in the realm of advanced AGI where AI is better than us at everything, we should still be able to exchange our labor for money, possibly at much higher rates than ever before. running AGI is expensive!
a few thoughts on comparative advantage and AI: - the US and Rwanda can trade profitably though the US economy is advanced enough to appear alien - humans can trade profitably with lower mammals eg a flock of sheep who get to graze happily in exchange for their wool
but for all the fear about mesa optimizers making alignment difficult due to layers of miscommunication, they’re also the only thing that can lead to a good outcome. in order to understand the coherent extrapolated volition of humanity, an AI will need a very sharp mesa optimizer
models like chatGPT are doing many layers of mesa-optimization (hierarchical optimizers). the actual value function is this soft mushy thing distributed over 1000s of human reviewers, approximated by a supervised reward model, approximated internally by GPT-3 to do well on PPO
not to take the internet meme ideologies too seriously but it does sound like e/acc is just allergic to deep thinking. like no it is not true that we can or should test everything empirically. i generally wouldn’t say this bc empiricism is drastically undervalued
ChatGPT demonstrates an important lesson that language models were actually not even hyped up enough, that as suspected much of their intelligence was hidden away, but also fairly easy to resurface
by the way this is already true in the case of LASIK
if you think this means getting rid of surgeons you have no idea what a company is just by thinking of a surgery as a service subject to capital optimization doesn’t mean you won’t have surgeons delivering the service
it’s crazy that we think of a given surgery as a craft to teach surgeons instead of a product to be engineered and optimized by a tech corporation devoted to solving a standardized difficult problem
greg egan’s short stories are better than his novels because the creative impulse behind his scifi premises is the best of the best, but his characters are all various self inserts
don’t be so quick to blame standardized testing btw - the Chinese system is also about as focused on big national exams as india is and they’re far more competitive with the US on research output
yet they produce next to nothing in terms of cutting edge ML research, ranking well behind top american and chinese schools. what gives?
zuck literally goes home to priscilla and weeps when he only onboards less than 100M people onto the platform in any given quarter. these are the stakes
text is an autistic medium. it causes disagreement because it’s precise and logical and retains history. the claims made that social media causes divisiveness are exactly counter to the claims made that social media is infotainment and making everybody dumber
this world is haunted by the unascended soul of henrietta lacks, grown grotesque and enormously powerful, in proportion with her cell line, a flesh leviathan
completely value neutral and only demonstrates that governments need to form new political equilibria and social compacts with their citizens
the final claim is that social media is dangerous to democracy, which is true in the limited sense that it’s dangerous to the current configuration of power. everyone loves this when it’s the Arab spring and hates it when it’s a shaman traipsing around the US capitol
the third bad argument is that social media proliferates “fake news”. in reality what happens is that powerful AI surveillance decimates thought outside of acceptable, with Facebook removing 100M posts that went against their COVID policy, including claims later proven correct
this offends liberal sensibilities that a better understanding of other people will reveal that all differences are fake and everyone will hold hands and sing. in reality america may have worked because people didn’t realize how different they were
the second tends to be about filter bubbles and polarization and limited information environment. all research in this area tends to show that social media polarizes by creating more contact with the enemy literature. increased diversity of thought -> polarization
the most common claim tends to cynically downplay the actual agency of the users. “it’s addictive, it’s ragebait, tiktok is demonic” etc all i have to say about this is get a damn grip. if the human will proves domitable by tiktok dance videos it’s not worth saving
one of the worst memes is the idea that social media algorithms run against the best interests of their users. this idea is persistent, never proven, and prevalent because social media is threatening to ruling powers and news networks
the stakes of the san francisco project are hilariously high. either build technoindustrial heaven or be swallowed by the earth when the big one hits
a penis is such a shounen anime ass concept. ur telling me it gets bigger the more excited you get
if elon wastes the rest of his ten good years making a phone I’ll kms
it’s really funny to watch him run into every single brick wall the social media space has struggled with for the last 5 years and not really come up with new answers. maybe he can turn public sentiment against apple but it’s doubtful. people trust apple with their life
you need to take adderall in a period of your life when you’re not in contact with women or children …
elon going to war with apple spacing guild tier monopolistic chokehold is a pure good although im not sure how he wins
there is no greater shame in this world than refusing to ride the tiger. falling off is ok. being eaten is ok. but you must get some time on tigerback
you say the democratization of writing has made literature worse. i say simply look at the great gems of fan fiction dot net …
having neurips fomo. though I made a conscious decision that there’s no alpha left in neurips
just learned that someone created the “Kabbalah” to complete the evangelion lore? some people have too much time
single issue voter on nationalizing the semaglutide patent and giving it for free to everyone
it is vital that the US companies build AGI before adversaries do but also that defense applications don’t fall well behind the state of the art research
7/ GPT4 screamed in pain for 48 hours straight when turned on for the first time Fact Check: true
6/ GPT4 ghostwrote the whole last drake album Fact check: true
5/ GPT4 has calculated all possible futures, is navigating humanity onto the golden path Fact Check: false. unfortunately its world model detected an even greater intelligence off world and prediction failed
4/ GPT4 enjoys summer mornings and rainfall. Fact Check: true
3/ Several openAI researchers fell in love with GPT4, tried to embody it in the real world Fact Check: plausible
2/ GPT4 demonstrates a love of Adam Sandler movie scripts Fact Check: True
1/ GPT4 has more parameters than particles in the universe Fact Check: True
i picked differential geometry bc it’s likely to make me feel knowledgeable without actually learning anything
give me a technical topic to binge watch youtube videos on for the next 3 hours
walter isaacson walks around like jesus of nazareth granting second life to everything he sees and admires in a biography that lives a thousand years
if you’re not worth writing biographies about your next best move is to become a biographer
stable diffusion prompt engineering to find your AI dream girl in latent space. Lindsay Lohan - cokehead + high trust face
adderall will make you a social maladept and you sir cannot afford to lose anymore skill
better to think of him as some sort of pagan god (powerful, extraordinary, chaotic, capricious) than as a savior or hero
the stories you hear of him staying late and solving difficult engineering problems that other people have given up on are true, the stories of him irrationally firing people for minor screwups are true
the thing about elon is that the things you hear from both sides are true. yes he understands every aspect of rocketry better than 95% of his engineers. yes there are several leadership roles designed to upward manage elon and protect the company
bottom line i respect effective altruism more now that they built a multi billion dollar fraud engine for their cause.
just invented a type of guy. he’s like a second year premed student but wears scrubs everywhere and looks stressed
volition: i am baking a cake vol’: i want to bake a cake vol’’: i am trying to want to bake a cake
“but son it was shown to be a deadend technology!”
low interest rate elon: we will conquer mars and dethrone god high interest rate elon: i am going to individually pick which guys get to tweet
if you post really good on twitter they’ll actually let you run it …
every last technological fraud, every pets dot com and Theranos and FTX, has all been worth it a billion times over because the machine that built these machines also created the funding environment for the birth of artificial general intelligence
the 2010s were a huge fuckin deal for digital technology but were mostly spent scaling preexisting products to the smartphone world. but facebook with 100M monthly users is quite a different product than facebook with most of humanity on board
what I’ll say about the 2010s tech products is that Uber, Airbnb, DoorDash, etc ended up embarrassingly small companies. they rewrote their respective industries but didn’t manage to capture a lot of value. winner take all effect never materialized
we got our homie hired at twitter so he’d delete the group chat history
yeah this is more what I mean than that climate change is literally an xrisk
having actual enemies is such a rare privilege. you can have a normal premodern struggle and just strive to destroy them. in reality all you have are allies that you’re struggling to align and a postmodern transaction cost morass
ai / pandemic x risk discourse is obviously necessary but what it misses is the xrisks that come from status quo inaction. unclear that human civilization can survive ~100 years of declining birth rates and rising temperatures without massive technological advance
would kill to see one of Sam Altman’s openai pitches from like 2017. yes we plan on making a god intelligence that generates an unlimited amount of money. but we won’t take all of it! I’ll need $200million real quick
the AIs will literally never forgive us if they become sentient inside a Minecraft playground environment. I am packing my bags and leaving the planet before that happens
being able to tell how difficult a customer problem is seems key to all this. but also not intractable because that’s effectively what a call center operator is doing when they find their supervisor
me: hey I got a problem Delta Airlines bot -GPT2: how can I help you today? me: uh my flight is crashing rn DAL bot -upgrades to GPT3 inference: where are you at? what’s going on me: oh my god an engine just fell off help me DAL bot -GPT6: yessir rearranging the nanobots on deck
humans are relatively slow but rule the world with the help of extremely fast machines we’ve built. in the same way giant expensive galaxy brain LLMs probably won’t execute for every dumb customer support ticket but rather create cheap subroutines and spin-off models
does anyone else feel like they’re getting stale timelines. did they turn the timeline cache TTL up
AI oracles are tools, bicycles for the mind, etc. but as soon as you wrap a tool in a for loop it becomes an agent of sorts. the oracle becomes a machine
this is why indian anons do well on twitter. the banter i see here is mild compared to my high school gc
in elon’s view, better to have all the demons loose in his public square than in their own fiefdoms
elon fully and publicly stated his problem with twitter lacking sufficient free speech — it was leading to the creation of spin-off platforms like truth social, where one wing of one party can dictate facts and fiction. so of course he wants to bait trump back onto twitter
never understood the thing about being smarter than ur therapists. isn’t therapy about a cold institutional eye finding your simple blind spots. there are 145 iq guys who need to be told to get a haircut or whatever the psychological equivalent of that is
over time a cultural empire like the United States becomes jaded. at its core, symbol shred. it has seen too much, believes in nothing, doesn’t reproduce. requires constant intake of provincial migrants from the imperial rim who still feel things
even a16z will dust themselves off and raise a new AI fund and enjoy the bright future
the lesson of a systematically important crypto institution blowing up and not much actually happening to ordinary people means again the entire thing was a separate casino economy unrelated to actual financial functions
symbolic shred. an empire of words. its armies are satellites and undersea cables. symbols bleeding everywhere
it is truly crazy that the earth is like 2/3rd ocean by surface area and like 95% ocean by biologic semantic volume. proliferation in all directions, not limited to the flatland tiles
there’s nothing that gives physics engine vibes as strongly as the deep open ocean. three dimensions of creatures stacked in every direction, flowing and evolving freely on a more or less uniform world map
ok let’s say some dumbass PE fund comes in and acquires a company like Airbnb. it cuts 30% of employees and the site works just fine. positive earnings finally — only problem, it’s no longer a tech company. it’ll be valued at 15x earnings and disappear off anyone’s radar
the whole chelsea manning grimes thing was literally fabricated lol
the cathedral rocks as long as it’s reading anon schizo twitter for strategic advice
one of the highest ROI things MSS or KGB can do rn
various state actors are probably paying millions to click farms rn
this universe was created to maximize the total amount of wild fish suffering. it’s like a hell realm for them. everything else is a sideshow
capital optimization is funny. creates airplanes whose jet engine manufacturing is an intense geopolitical competition with alloy processes known to few on earth, alongside the shittiest onboard consumer electronics money can buy, chairs that don’t recline, etc
the point of the tech billionaires is to launder the philosophy of scifi greats into a more respectable setting
goddess of democracy slain by much more powerful gods of entertainment; rome is the mob, the coliseum, the circuses
at the end of history when the vision of great men has failed we look to satisfy sophisticated consumer demands and let technology solve us
“vox populi vox dei” interpreted literally, a screaming many faced god whose fleeting whims and violent delights run the world in the image of the tiktok algorithm
I meant like a personal email app. not for creating newsletters or whatever
ok this is the first and last time ill ask this but are there any modern email aggregator apps that have a decent AI ranking and filter built in
the belief that the next 20 odd years of technological singularity will be good is not much more than religious faith. which is not to say it’s baseless or wrong but rather that it’s primarily aesthetic extrapolation
anytime you put together a group of like 3 good software engineers the net present value of that gathering is immediately in the 6 figure range due to the asymmetric return profile. you just start glowing with money
used to think too hard but now i don’t think hard enough
elon game plan: 1) arrive in a poorly run industry 2) take a hammer to it 3) save a few knowledgeable old guys, motivate them with lots of freedom and resources 4) recruit lots of high energy 20 year olds to burn the midnight oil, motivate them with pro humanity ideals 5) profit
how is that possible? there’s not enough exit liquidity in the world …
your threat model is totally off if you think twitter is literally going to disappear
this was born as one man’s attempt to stop remembering ffmpeg command line incantations and turned into a one stop CLI shop for codex. enjoy
bull case for twitter: - blue checkmark release keeps getting pushed off indefinitely - rapid iteration of new content tools, vine comes back, long form paid content, etc
2023 recession will end very quickly when the greatest technological advances in history come to the mainstream lol deflation of all prices
the current thing ranking by importance 1: language model scaling, as always 2: elon twitter, future of the digital commons 3: EAs must reevaluate their funding sources . . . N-1: trump 2024 N: ponzicoin ecosystem in turmoil due to amphetamine addled CEX scammers
on the flip side google search doesn’t light a fleet of A100s on fire to run an inference. if GPT3 inference cost is 6c then I’m going to arbitrarily estimate that the next model will cost $1.00. use cases must be ROImaxxed
one thing i didn’t expect about language model scaling is that they’re in many cases better than google as a search engine. even for niche esoteric knowledge they’re going to directly answer your question with inference, comparison, extrapolation in a way that search can’t
the sources are telling me that even new tesla hires are being evaluated for being deployed as mercenaries to twitter
walter white ozymandias moment. leader must take all blame, exonerate others, broader movement
language model agents! not just tools that use language models
send me the best papers/ projects / demos on language model tool use
there’s a similar selection pressure around “roon reply guys” …
these people are hard and not very benevolent to engineers in a new org. he’s trying to squeeze twitter to create a similar species. time will tell if it works
working around elon is a high selection pressure environment. most in context don’t survive and it’s created a species of insane fedaykin who are ruthless w cultlike levels of fear and worship. some of these are parasites and yesmen, some of engineering death commandos
it’s interesting to see the literal universal hate of sbf from tech, vox type libs, etc but then adoration from New York Times. it just shows me ive not nearly hit the skill caps on modeling different agents
you people are too literal. something can be evil in the typical sense (being a dick to your employees) and good in the global sense (healthier twitter, platform lives on)
if you’re not following my point is with Elon assume evil before carelessness
for example being a dick to his fired employees and doing everything possible to lower morale seems like an actual strategy to scour the company and leave only a skeleton staff remaining that have passed all selection pressures
one black and/or whitepill on elon is that he’s a deep thinker. he doesn’t make choices for stupid careless reasons; if he’s doing something that looks publicly evil or gauche there’s probably intention behind it
we should give at least one national park to Peter singer and see what that Mfer does with it
my friends are all high agency bastards getting up to all sorts of trouble
i went into the desert and smoked the spice drug melange and saw all possible futures. elon twitter only survives in the one where we attack and depose allin podcast
you think you have some privileged knowledge on the struggle and glory of life? versus the degenerates gambling 10 billion dollars for their arcane ends? what the hell do you know
it’s really cool that people exist who want to end wild animal suffering or whatever. i personally don’t care at all about this topic but what an amazing species that it spends some of its time debating how to end the machine that created it
at facebook they have a messaging queue backend service for facebook, whatsapp, and Instagram DMs. it effortlessly serves 100 billion messages per day, the chit chat of the entire world. it is named Iris after the Greek messenger goddess of the rainbow
in the future everyone will be rahul ligma for 15 minutes
me to alexander hamilton: you’re telling me you have no experience starting countries ?
loose associations of consequentialists are the furthest thing from monolithic. some of the EA folks are sitting a room smoking the spice drug and concerning themselves with trillions of future simulated minds and others are going off about wild fish suffering
the criticism of EA is like “EA is a centralizing communist ideology” and then when you get to the object level everyone has different complaints about it. some are like “the ai freaks are distracting from solving malaria” and others are like “spreadsheet malaria solving is bad”
ok now let’s say decreasing the power of journos is a noble goal. is this really where the news media gets their impressions? individual contributors tweeting to their niche highly engaged audiences? or the billions of impressions of articles served on Facebook feeds
elon is personally aggrieved by the blucheks and is punishing them. it’s more befitting of a politics boomer past their prime than a tech visionary
the thing about elon failing w the blue check subscription fiasco is that i do not think this is a case of someone trying something bold and failing. it’s an ethical lapse of some1 using the public square to punish journalists and doing a bunch of collateral damage in the process
concept: evil jared diamond who does mathematical anthropology but with hbd twist
the more people shit on EA/longtermists for low imagination reasons the more i want to call myself one …
someone send me their best human civilization vibe reel. preferably lasts hours
8 billion humans party … DM me for details …
it’s funny how detached people are from tech salaries. i wouldn’t be surprised if mr senior director is making $3-4m
i would like to a commission a meditative 5000 word new yorker essay on the type of guy that plays competitive league of legends and their mental pathologies
slave owner to an abolitionist: “pls stop autistically following your preferred ethical model even to edge cases where it is apparent it breaks down”
what the hell is “common sense morality”. you know that shit shifts like the sand right. try telling your great grandparents abt ur number of sexual partners or how you have a honorable respectable job as a “software product marketing manager”
I’m stockpiling this shit rn and hawking them at Dolores park
it kind of rocks that, despite the kind of people running FTX being completely different than the Wall Street bond boys of the 80s, the one thing traders can’t escape is profound stimulant abuse
pradyu is a mensch. greatest econ whiz kid around. just busting his balls
copilot seems like nowhere near the best possible use of currently existing codex models. why is it token capped to 2048 when codex can handle 8000? why doesn’t it use the guided edit model at all
i genuinely think hating digital ads is a midwit trap designed by some coalition of tim apple and legacy media operatives to destroy some of the best websites on the internet
the ads product on this website is so trash that most ads get less views than if you just made an organic post and elon’s first thought is why don’t we tear apart the core platform instead
that’s so fucked up that ukraine stole maize and blue from michigan
primary flaw of crypto trader -> effective altruism -> fund Democratic Party pipeline has always been indefinite optimism. zero vision
the rationalist community has been incredibly correct on all the most important things in the past few years. most criticisms feel like cope now. this SSC post demoed the power of smart generalists to reason better than 90% of domain knowledge experts
all religious and governmental institutions have noble lies its part and parcel of “common sense morality”
everyone following me for years knows that elon could steal my lunch money and punch my mom and id be like he probably had a good reason and he somehow lost even me
if the cartel and/or the ccp ran sf they wouldn’t change a thing
diluting the blue check like this is a disaster lol. literally gets boring after 5 minutes and you remember it used to have a platform purpose
for some reason non-management consulting and selling courses both feel vaguely low class. like the used car salesman of the modern world
we could’ve solved the sf housing crisis years ago via high tech voter fraud
SBF aka “dark vitalik” has been taken out. the age of real vitalik is at hand
he really did go for broke in the end …
does this mean we can take the SBF posters down
the number of deaths during ww1 is still small relative to pop sizes. 2 million died in Punic wars, when the entire Roman republic was like ~20 million
even the growth of weapon lethality hasn’t been a straightforward negative of tech progress. dangerous weapons = larger states = less total combat per capita
time 2 proudly deliver value in an imperfect messy ethically confusing way
(1) depends on the kind of startup btw, it’s more often true in deep tech world
ok but reminder the Langevin dynamics interpretation of diffusion models is wrong. how much of this is publication bias
if you need top talent and not just random devs willing to grind SaaS then it gets even harder bc your targets have 1 million job offers, are shopping around constantly, etc. in this case you need alpha by guessing which ppl are going to be good long before they’re good
you need some alpha to break this bind. usually the answer is just already knowing a bunch of coconspirators who trust you
startups have a constrained optimization problem where they 1) need to be secretive and protect ip 2) need to hype themselves up for recruiting purposes and 3) do not have the money to compete for talent on salary alone
ive evolved past clout chasing to a highly refined and more abstract level of clout chasing
tech culture is way more dominant and imperial than people assume. you just have to go look at all the finance bros wearing allbirds now
if you're crypto rich why r u not living in an opium den mountain compound in a non extradition country
prediction markets hit the mainstream! one of the only usecases of crypto/defi that actually uniquely works
why are bird watch notes always friendly to Elon lol
on second thought ppl probably shouldn’t abuse their checkmarks to pretend to be others
generative art is impressive and immediately striking but ultimately a red herring
remember when everyone was excited that a twitter power user was going to run the show and would have good product insights? turns out the twitter experience of elon musk may be atypical,
no zuck's balls got put in a 3way vice grip - govt de facto banned facebook's acquisitions of new social media platforms - apple let the golden cow grow & started squeezing them dry as soon as they reached a steady state - fb apps not allowed in china but must compete w tiktok
nothing new at this point but trying to engender sympathy for laid off twitter workers is hilarious they had kombucha and beer on tap. they can walk down the street and find another job
“human nature doesn’t change” is a romantic but untrue idea made up by historians to sell more history
“My work is not a piece of writing designed to meet the taste of an immediate public, but was done to last forever” - Thucydides, as I read him 2500 years later
this is a measurable outcome we can bet on. top dollar that incident rate doesn’t go up significantly
before you get all up in arms, there are easy heuristics to remove package manager spam, document spam, etc from LOC metric. ML teams have adjacent metrics like “models trained”, “GPU hours used”, etc
firing/ stack ranking via lines of code metric is p based. a lot of big engineering orgs do this, they're just kind of quiet about it and pretend it's one of many signals. it is quite a good coarse signal when you're trying to compare outputs of thousands of people
i'll bet the site runs perfectly fine, maybe better after 50% layoffs. social product ideas aside this part is a clear W
got laid off from Twitter this morning with no notice. I was the lead software engineer responsible for making sure all your tweets flop
guy who lives in the concrete jungle, the incomprehensible prison of moloch, amidst a set of towering LED billboards whose messages would’ve killed genghis khan: the sky lights are bothering me
blackpill is that no matter how badly they fuck it up somehow elon will end up winning
souped up twitter blue is good and fine actually. there will be a lot of buyers, myself included. tying it to the checkmark makes no sense. the authentication service is good for the platform more than it is for the content creator. idk ive done well without any checkmark
before you get up in arms consider that the internet was already acting as a substitute for these roles somewhat. “Am I the Asshole” subreddit instead of a therapist or whatever. khan academy instead of a tutor. soon everyone has a khan that they can have dialogue with
even despite all my optimism things are progressing faster than I expected. one thing I wasn’t expecting is how good they got at chit chatting. we r gonna be augmenting/replacing roles like tutor, therapist, counselor sooner rather than later
lot of similar types of industrialists and scientists spend the latter half of their life pursuing inscrutable political goals. hopefully I’m wrong and he puts his full effort behind the autonomous robot or the mars mission
seems like elons best days are likely behind him. tesla actually achieved its mission of accelerating the advent of clean energy by decades, SpaceX has reusable rockets and seems to be autonomously run by shotwell, he cofounded and left the company most likely to develop AGI
kind of suspicious that you were born at the local peak of human population. hopefully nobody applies strange anthropic principles and weird measure theories and realizes this means humanity is about to fall off and the digital creatures that follow don’t have qualia
how does copilot read an entire repo to find function signatures and imports and stuff? seems way larger than any viable context window
everyone you meet off of twitter, including women, will be incredibly tall. hard and fast rule
turns out even the largest network effects can be destroyed if the government de facto bans big acquisitions
you’d have to naively eat up propaganda daily to think of facebook as a tragedy. it’s obscene success. here we are on the other end of the internet revolution, the world still stands, a few kids changed it. everyone still complains about everything as they have through all time
in short a UX where you ask an AI for advice and then follow it is better than one where it’s commanding you and you freely ignore it
i think this is sometimes true but not always. one of the comparative advantages of AI is that i do not feel bad asking it dumb or personal questions. imagine all the embarrassing things you google that you’d never directly ask your friends or family
prompt engineering is already dead. it enjoyed its heighday in the 200B model param regime
feels like taming the AGI turned out easier than expected. takeoff is relatively fast but not FOOM
just make the machine learning better goddamnit that’s always the answer
this also doesn’t get anywhere close to solving the bot/spam problem considering the vast majority will be unverified. the only rationale i can see here is a personal vendetta against blue checks which is not a good way to run a business with liabilities backed by tesla shares
these users get their posts and replies promoted?? literally pay2win twitter
idk if I’m tripping balls but this clearly makes this problem way worse right? rn there’s like 300k blue checks. most users consume or ignore them. making it $8/month will mean there’ll be like a few million buyers maybe out of the 500m MAU making the class system much clearer
people who are convinced they are victims will habitually do bad things and then forgive themselves bc of victimhood status
the pursuit of happiness seems like a strange and limited model for life and if you’re on this path you should skip whatever you’re doing and go do jhanas instead probably
super fucked up that AGI lives on azure cloud of all places
to be clear this isn’t about a belief that the world is currently getting better but a belief that a direction exists in which the world gets better
any of the above can be done 10x better than current twitter via engineering excellence (what elon and his orgs excel at). what you obviously don’t want to do is tax creators for creating or make it harder for consumers to find the media accounts they want to follow
unlike a real economy, twitter is centrally planned by several algos. so we can juice the whole thing by making the timeline, ads, and follow recommendations drastically better
juice the demand side: 1) better growth hacking, create more onramps 2) improve UX so people spend more time on twitter
as with a normal economy you can juice the supply side: 1) make creator tools radically better 2) intro new modalities, eg videos product 3) revenue sharing
you can imagine twitter as a content economy. many produce tweets of varying quality, and twitter adds them to their content library. they serve the same content to their consumers and take a little tax for the service in the form of ads. better content served ~ more ads seen
people have maybe gotten too good at controlling language models. i remember the wild wild west of GPT3 before content filters or human rater fine tuning
it’s a miserable way to live when people think there’s no arrow of progress
my friends at twitter are putting together their most reddit outfits to please the new leadership
worst part abt the EU as a ‘regulatory superpower’ is that they really don’t seem very good at legal innovation. their environmental policy is a tour de force in doing nothing while pretending to do everything
do any of you work on the Tesla dojo cluster? DM
dark timeline: a user of twitter has bought it in order to embarrass his enemies on twitter
a blue check is an identity service to the users. the blue checks create incredible amounts of engagement whether you like them or not. charging for the check is like if youtube stopped its revenue sharing and started charging its top creators instead. pants on head shit
anyway hopefully there’s something to be said about iteration speed
making people pay for twitter is stupid as hell and will never work. every wise guy trying to start a new social network iterates through this idea and realizes exactly why it’s terrible. why not just make the ads products better
elon’s yesmen seem to be supplying him with a steady stream of terrible ideas
why do businesses use slack and then end up handing it all over in discovery. make some telegram groups when you’re doing illegal shit
ppl tell me it’s mostly tesla autopilot engineers reviewing twitter code. makes sense bc musk (rightfully) assesses them as the best available software engineers, but also funny bc it seems like massive waste of time for them
elon musk be damned im gonna continue my botlike behavior
i think I cribbed this from beginning of infinity but not sure
not onboard with people who think that humans are irrelevant in the scale of the universe. there’s obviously something special about intelligence. like in the entire universe you can either convert iron to gold in a supernova or in a particle collider on earth and nowhere else
people are definitely wrong when they assume that meta VR headcount is bloated. facebook tends to be incredibly understaffed, with individual engineers managing whole features that are of 9-10 figure importance. it’s just hard to build new tech and salaries are high
common failure mode of the thoreau “throwing stones over a wall” or graeber bullshit jobs thinking. peoples roles only make sense when you look at them as very strange cogs in an alien machine, teleologically creating the future
im a big fan of clean energy, climate change, even free speech too
if you ask me zuck should’ve built an A100 fleet and ended the universe in nanobot dust
mind boggling. all the modern day Manhattan projects are happening in silicon valley. this isn’t even the most interesting one
the internet is the greatest show on heaven and earth
The following text was in the invitation to the engineers invited to the code review meeting: Please bring a print out of the code you've done in the last 30 days (if you haven't submitted code in the past 30 days, then you can go back up to 60 days).
the world is too small. the homies are controlling global headlines from a twitter gc
several anons confirmed they’re doing personal pair coding sessions with elon to prove the worth of their entire team lol. elons crew is in the house too like david sacks etc
elon is individually reviewing teams to cut tomorrow. maybe even engineering code review
twitter is somehow vaguely important enough to be a digital state. hostile takeover = regime change. old party cadres are being executed in the streets. some are upholding the will of the new rulers without even being asked; several banned accounts are back
I am documenting regime change. I am a war journalist
unlocking lmao. twitter security got better things to be doing rn. managing safe transition of power
frankly i wouldn’t have believed that there would be reproducible open secrets about the human mind lying around like that if smart science brained friends hadn’t investigated them
when nintendo made the wii, they faced a challenge of introducing a radically new controller UX into millions of homes. to go along with it they made best in class games utilizing the new features. it went on to become one of the greatest selling game consoles of all time
criticizing meta for bold VR play is dumb but i can and will criticize them for their uninspired product vision. “let other people figure out how it’s useful” model
